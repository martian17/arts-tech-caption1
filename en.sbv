0:00:00.000,0:00:02.499
Of the use of artificial intelligence

0:00:02.499,0:00:05.009
in our societies

0:00:05.009,0:00:07.475
So today

0:00:07.475,0:00:12.571
Let's go back to today's discussion and workshop

0:00:12.571,0:00:15.950
I'm very much looking forward to do it of course

0:00:15.950,0:00:22.545
And I would like now maybe to give the flow to Jean-Yves Iatrides to say a few words

0:00:22.545,0:00:28.054
On the side of Air Liquide before moving to the representatives of Japanese embassy

0:00:28.054,0:00:30.000
Jean-Yves, the floor is yours

0:00:30.000,0:00:33.696
Thank you Sebastian, I hope you can hear me

0:00:33.696,0:00:36.894
Good morning, good afternoon, konnichiwa to all of you

0:00:36.894,0:00:42.931
So I'm Jean-Yves Iatrides, so I'm located in Japan

0:00:42.931,0:00:49.426
And I'm, in charge of the R&D activity for the Air Liquide Group for the Asia region

0:00:49.426,0:00:59.522
Thorough that as Sebastian said, it could look a bit strange to see Air Liquide as being part of this event

0:00:59.522,0:01:07.257
In fact, first of all, what is Air Liquide for the ones which don't know Air Liquide, or our colleagues in Japan maybe

0:01:07.257,0:01:10.739
Air Liquide is a company supplying industrial gases

0:01:10.739,0:01:15.396
In fact, we have been in Japan for more than 100 years

0:01:15.396,0:01:17.441
So we're not a newcomer in Japan

0:01:17.441,0:01:22.630
And of course being part of this exchange program with France and Japan

0:01:22.630,0:01:25.327
Is, I would say of use for us

0:01:25.327,0:01:27.806
And that's one reason

0:01:27.806,0:01:30.190
The second reason is that some hard innovation

0:01:30.190,0:01:37.058
As we know the heart of the company, and the company has been created a long time ago by an inventor

0:01:37.058,0:01:39.155
Which has been exploring in many fields

0:01:39.155,0:01:45.185
And I'm sure at least in some point of his career he's been catching the art also

0:01:45.185,0:01:50.710
And now what is very much the focus of the group

0:01:50.710,0:01:53.067
Is of course we need to transition

0:01:53.067,0:01:56.421
With the development of the hydrogen society

0:01:56.421,0:02:00.976
But also looking at any technology

0:02:00.976,0:02:04.979
that will allow us to develop a system that build future

0:02:04.979,0:02:09.671
And this question of AI is definitely one of the topics

0:02:09.671,0:02:12.861
that is very important in out minds

0:02:12.861,0:02:17.772
So the topic of the day is definitively

0:02:17.772,0:02:24.828
not directly linked between AI and the, we say unusual operation that we have in the company

0:02:24.828,0:02:28.754
But we have a feeling that such technology

0:02:28.754,0:02:30.953
or such new technology I would say,

0:02:30.953,0:02:32.507
which is really disruptive

0:02:32.507,0:02:41.759
Addressing, certainly the way we feel, we touch, (and) we get in contact with the things

0:02:41.759,0:02:47.601
cannot be only looked at from a short point view, or from a technical (or from) an engineer

0:02:47.601,0:02:51.272
I'm a very bad artist I'm an engineer

0:02:51.272,0:02:55.623
you know, dealing with numbers, dealing with mechanics, dealing with these kinds of things

0:02:55.623,0:03:03.831
But I'm still convinced that when we touch technology, and new technology especially, in the digital world

0:03:03.831,0:03:06.455
we have to look at it from a different angle

0:03:06.455,0:03:12.103
And this is one of the reasons we have been funding this and this year's program

0:03:12.103,0:03:16.501
at the Fondation France-Japon since the beginning of the creation

0:03:16.501,0:03:23.783
was to be about to approach topics from a more human science point of view

0:03:23.783,0:03:28.664
And honestly (that's uh) I think it's very interesting

0:03:28.664,0:03:30.811
it's complementary to what we do

0:03:30.811,0:03:34.586
And therefore I'm very delighted to be part of you today,

0:03:34.586,0:03:37.787
To listen I would be mostly listening

0:03:37.787,0:03:43.764
But again I had the opportunity to meet Eto-san in Paris

0:03:43.764,0:03:46.026
a few months ago when I was visiting Paris

0:03:46.026,0:03:51.578
And it was really interesting and I think we had a very nice discussion at our research center in Paris

0:03:51.578,0:03:56.057
And I think I'm looking forward for the presentation of today

0:03:56.057,0:03:57.977
Thank you very much for the invitation

0:03:57.977,0:04:01.374
Thank you, thank you very much Jean-Yves for your kind words

0:04:01.374,0:04:09.595
So now I would like to, before (the) what you are waiting for and you expected before the talk by Eto-san

0:04:09.595,0:04:16.030
I would like to give the floor to Mr. Takenouchi from Japanese embassy in Paris

0:04:16.030,0:04:21.325
to say a few words in the name of the Japanese authorities

0:04:21.325,0:04:26.287
Thank you for the kind introduction, My name is Yosuke Takenouchi

0:04:26.287,0:04:31.880
In charge of science and technology policies at the Embassy of Japan in France

0:04:31.880,0:04:35.132
And first of all, on behalf of the embassy,

0:04:35.132,0:04:40.660
I would like to congratulate you on the successful organization of today's workshop

0:04:40.660,0:04:45.903
As Covid continues to impose restrictions around the world

0:04:45.903,0:04:53.027
Science and technology-related events like this are still not as active as before

0:04:53.027,0:05:00.825
And under such circumstances I'm such delighted that today's event has come to be held

0:05:00.825,0:05:05.037
And I guess it was not an easy task to prepare

0:05:05.037,0:05:12.309
So I would express my sincere gratitude especially to Doctor Koichiro Eto

0:05:12.309,0:05:14.309
and Fondation France-Japon

0:05:14.309,0:05:19.396
and Air Liquide, and all the members involved for their efforts

0:05:19.396,0:05:25.023
And looking at the science and technology policies of both countries

0:05:25.023,0:05:29.864
In France, a research planning law has been enacted

0:05:29.864,0:05:35.849
That sets out the ten year research strategy starting in 2021

0:05:35.849,0:05:43.226
And similarly Japan has just formulated the science technology and innovation basic plan

0:05:43.226,0:05:49.505
which will run for five years starting in 2021 as well

0:05:49.505,0:05:59.588
And the main pillars for both plans are social transformation and strengthening of research capabilities

0:05:59.588,0:06:03.102
And education and human resources development

0:06:03.102,0:06:07.302
And I see there are so many similarities

0:06:07.302,0:06:11.557
In the challenges that Japan and France are facing

0:06:11.557,0:06:15.996
And needless to say among the social transformation

0:06:15.996,0:06:19.175
Brought about by advanced technologies

0:06:19.175,0:06:22.995
The impact of AI is enormous

0:06:22.995,0:06:27.610
And this is evident from reading the AI strategies

0:06:27.610,0:06:30.067
established in both countries

0:06:30.067,0:06:39.838
And discussing how we can make rapid social transformation more acceptable to society

0:06:39.838,0:06:46.198
is as important matters as technological development itself

0:06:46.198,0:06:52.148
So I understand that the theme of today's workshop is

0:06:52.148,0:06:57.844
to pursue the role of art as a solution to this question

0:06:57.844,0:07:01.697
which is a very interesting point of view

0:07:01.697,0:07:07.682
And I look forward to the presentation and the discussion of the participants today

0:07:07.682,0:07:12.191
And finally I would like to conclude my greetings

0:07:12.191,0:07:17.503
with a wish that today's workshop will be an opportunity

0:07:17.503,0:07:22.321
for our new collaborations across research fields and borders

0:07:22.321,0:07:23.561
Thank you very much

0:07:23.561,0:07:29.441
Thank you very much for your kind words Mr Takenouchi

0:07:29.441,0:07:36.402
And now it's time to give the flow to our colleague and friend Eto-san

0:07:36.402,0:07:44.048
so we hope you will enjoy this workshop

0:07:44.048,0:07:46.324
and enjoy the discussion as well

0:07:46.324,0:07:49.517
so the floor is yours, Ito-san, (in Japanese) douzo

0:07:49.517,0:07:54.031
Oh thank you very much. My name is Kouichiro Eto

0:07:54.031,0:07:58.866
And first, I would like to say thank you to all participants

0:07:58.866,0:08:01.785
Especially both speakers and audience

0:08:01.785,0:08:08.046
So I would like to start my presentation without further moment

0:08:08.046,0:08:17.128
Okay, I would like to start my presentation

0:08:17.128,0:08:24.860
My title of the presentation is "Art brings the future to our society"

0:08:24.860,0:08:31.648
And I am a 2021 FFJ/Air Liquide Fellow at Fondation France-Japon

0:08:31.648,0:08:34.802
And also I am a researcher at AIST

0:08:34.802,0:08:44.367
First of all, I would like to thank everyone who helped me make this workshop possible

0:08:44.367,0:08:48.194
First I would like to thank Mr, Jean-Yves Iatrides

0:08:48.194,0:08:50.260
from Air-Liquid corporation

0:08:50.260,0:08:54.886
and professor Sebastien Lechevalier from Fondation France-Japon

0:08:54.886,0:08:57.820
who made this fellowship possible

0:08:57.820,0:08:59.467
Thank you very much!

0:08:59.467,0:09:04.057
And I would like also to thank to my colleagues at FFJ

0:09:04.057,0:09:08.971
Fabien-san and Itoh-san, Jodie-san, and my colleague in Japan

0:09:08.971,0:09:10.971
Thank you for all

0:09:10.971,0:09:15.899
Before getting into the main topic

0:09:15.899,0:09:19.167
Let me explain the differences from the original plan

0:09:19.167,0:09:25.067
The initial plan was to investigate the cognitive differences in AI between Japan and the West,

0:09:25.067,0:09:30.275
However, it turned out to be difficult due to the reasons shown here

0:09:30.275,0:09:33.973
Therefore I have shifted the plan

0:09:33.973,0:09:37.028
I have defined the final objective

0:09:37.028,0:09:43.969
to investigate the relationship between AI and advanced technology in Europe

0:09:43.969,0:09:46.163
I appreciate your understandings

0:09:46.163,0:09:50.997
First, let me introduce myself

0:09:50.997,0:09:54.276
I have been working as an artist since the 90s

0:09:54.276,0:09:59.989
Then in 2002, I joined AIST and started working as a researcher

0:09:59.989,0:10:04.485
I would like to introduce two of my works

0:10:04.485,0:10:09.978
they are in common that they are works that they make the internet visible

0:10:09.978,0:10:17.000
This work is "Web Hopper"

0:10:17.000,0:10:19.619
You can see a world map on the screen

0:10:19.619,0:10:23.876
On this map you can see the user's web hopping trajectory

0:10:23.876,0:10:29.212
For example, let's say you are looking at a website in the US

0:10:29.212,0:10:32.457
Then you click a link to a Europe one

0:10:32.457,0:10:37.094
Then virtually you have jumped from the US to Europe

0:10:37.094,0:10:41.388
By analyzing internet traffic in real time

0:10:41.388,0:10:45.450
I could visualize the trajectory of web browsing

0:10:45.450,0:10:49.711
we published this work in 1996

0:10:49.711,0:10:53.017
we won the grand prix of Prix Ars Electronica

0:10:53.017,0:10:58.868
At that time, the work became a permanent exhibit

0:10:58.868,0:11:00.425
At the arts Ars Electronica center

0:11:00.425,0:11:05.395
We won the grand prix of Press Electronica

0:11:05.395,0:11:09.439
the press prize is the most prestigious award in this field

0:11:09.439,0:11:15.310
this exhibit is a hands-on model of the internet

0:11:15.310,0:11:19.176
This work shows how internet works

0:11:19.176,0:11:22.623
You can see a white table in front of you

0:11:22.623,0:11:24.737
And this is a terminal

0:11:24.737,0:11:29.371
Here you can make a packet with black and white balls

0:11:29.371,0:11:32.009
the first 8 balls are for an address

0:11:32.009,0:11:35.046
and the last eight balls are for data

0:11:35.046,0:11:39.270
You can only send one character at a time

0:11:39.270,0:11:42.570
Then press the "send" button

0:11:42.570,0:11:48.196
The packet goes through the internet

0:11:48.196,0:11:52.509
And the router moves the packet from the local area network to another network

0:11:52.509,0:11:55.794
So this is a routing table

0:11:55.794,0:12:03.040
And then a packet go from the (terminal) out to the internet

0:12:03.040,0:12:07.031
Then this is the destination terminal

0:12:07.031,0:12:10.680
The packet goes to the display of the terminal

0:12:10.680,0:12:19.051
Then the packet go into the display

0:12:19.051,0:12:25.918
You can see the content of the packet

0:12:25.918,0:12:28.012
which is a character "A"

0:12:28.012,0:12:32.485
We created this work in 2001

0:12:32.485,0:12:36.245
and you can still see it in the museum in Miraikan

0:12:36.245,0:12:40.242
If you have a chance to visit Tokyo

0:12:40.242,0:12:42.493
please drop by Miraikan!

0:12:42.493,0:12:49.781
What I would like to explain here is a period in the 90s

0:12:49.781,0:12:53.257
This age was a very early stage of the internet

0:12:53.257,0:12:56.775
At that time, the internet was an advanced technology

0:12:56.775,0:13:01.305
These works explain how the internet works

0:13:01.305,0:13:03.272
for the general public

0:13:03.272,0:13:09.533
Since 2002, I have been a researcher at AIST

0:13:09.533,0:13:15.298
continuing a research theme, how we can design a press for co-creation

0:13:15.298,0:13:23.259
The key concept of my research is that the users should design the system

0:13:23.259,0:13:27.598
This picture is of a famous architect Christopher Alexander

0:13:27.598,0:13:32.086
He said that the users should design the architecture

0:13:32.086,0:13:36.470
If we do that, we won't need architects anymore

0:13:36.470,0:13:41.023
Instead, he created a pattern language

0:13:41.023,0:13:43.309
to make this concept possible

0:13:43.309,0:13:46.413
a method to design architecture without architects

0:13:46.413,0:13:50.195
this idea is a key concept of my research

0:13:50.195,0:13:55.375
We created several co-creation platforms

0:13:55.375,0:13:58.685
that connects various fields based on this concept

0:13:58.685,0:14:03.025
The most significant achievement was the Niconico-Gakkai beta

0:14:03.025,0:14:09.218
We created a platform that connects the general public with professional researchers

0:14:09.218,0:14:14.642
Even if they are not working as professional researchers

0:14:14.642,0:14:16.959
there are still people doing research

0:14:16.959,0:14:19.964
We call them "Wild Researchers"

0:14:19.964,0:14:25.093
And we created a press for them to present their research with us

0:14:25.093,0:14:30.976
We started this project in 2011, and held 9 large scale symposiums

0:14:30.976,0:14:37.170
The first symposium attracted 110,000 audience on the internet

0:14:37.170,0:14:42.754
The total number of viewers was over 658,000 (615,000?) people

0:14:42.754,0:14:47.905
Since then I have expanded my activities as follows

0:14:47.905,0:14:55.327
I would like to share the latest research result of our research

0:14:55.327,0:15:01.031
In January of this year, we published this paper to classify

0:15:01.031,0:15:05.436
74 facial emojis on the valence-arousal axes

0:15:05.436,0:15:08.464
Pleasantness and intensity

0:15:08.464,0:15:14.689
We published this paper in Scientific Reports, and it is press released from Nature Asia

0:15:14.689,0:15:23.908
And now I would like to start explaining this fellowship result

0:15:23.908,0:15:29.805
First, I set the research question as "What is the role of art in advanced technology?"

0:15:29.805,0:15:35.239
then I would like to move onto the background, method and findings

0:15:35.239,0:15:43.258
First, there are already some pioneering studies on the relationship between AI and art

0:15:43.258,0:15:50.706
First of all, there is a book "AI for creation" by professor Nao Tokui from Keio University

0:15:50.706,0:15:53.211
He is also a speaker at this workshop

0:15:53.211,0:15:56.475
His book is a very detailed description of

0:15:56.475,0:16:00.523
how can we use AI to develop human creativity

0:16:00.523,0:16:03.779
Also, professor Sofian Audry's book

0:16:03.779,0:16:05.851
"Art in the age of machine learning"

0:16:05.851,0:16:07.692
is published last year

0:16:07.692,0:16:12.229
Go back to the history of the computer art

0:16:12.229,0:16:14.916
This research is also excellent

0:16:14.916,0:16:24.520
Also the MDPI journal "Arts as a special institute" on "The Machine as Artist" in 2019

0:16:24.520,0:16:29.451
which includes 17 people's 17 papers

0:16:29.451,0:16:31.615
all of which are very worthwhile

0:16:31.615,0:16:38.787
And let's start with an explanation of observations in Europe

0:16:38.787,0:16:43.881
I visited various events and centers where arts and science are related

0:16:43.881,0:16:52.031
Ars Electronica is the most significant example in Europe

0:16:52.031,0:16:58.286
This center began as a Media Art Festival in 1979

0:16:58.286,0:17:00.833
the oldest and biggest in the world

0:17:00.833,0:17:05.840
They started Prix Ars Electronica in 1987

0:17:05.840,0:17:10.203
the award is the most highly regarded in the media-art field

0:17:10.203,0:17:17.751
In 1996, they opened the Ars Electronica center as shown in this picture

0:17:17.751,0:17:20.994
And they also started an R&D center

0:17:20.994,0:17:23.816
called "Future Lab" in the same building

0:17:23.816,0:17:28.483
But my relationship with Ars Electronica is strong

0:17:28.483,0:17:32.173
I recieved the Prix Ars Electronica three times

0:17:32.173,0:17:34.811
Including the Grand Prix of 1997

0:17:34.811,0:17:42.938
From my point of view, the most significant result of future lab is Spaxels

0:17:42.938,0:17:47.894
They started the project in 2012

0:17:47.894,0:17:52.317
to draw pictures in the sky using drones

0:17:52.317,0:17:55.372
They named this project "Spaxels"

0:17:55.372,0:17:58.296
The meaning is "pixels in space"

0:17:58.296,0:18:03.398
I saw the initial launch event at Linz in 2012

0:18:03.398,0:18:10.618
In honest, I felt that the light was so weak and unreliable at that time

0:18:10.618,0:18:13.670
But this project grew steadily

0:18:13.670,0:18:18.474
In 2015, they started a joint research with Intel

0:18:18.474,0:18:21.388
And they developed this project far away

0:18:21.388,0:18:28.436
In 2021, Intel drew a symbol mark of Tokyo 2020

0:18:28.436,0:18:31.270
At the opening ceremony of Tokyo (Olympics)

0:18:31.270,0:18:39.515
And they held the Ars Electronica festival in 2021 again

0:18:39.515,0:18:41.820
but it was a hybrid event

0:18:41.820,0:18:47.051
Usually the festival attracts so many artists from all over the world

0:18:47.051,0:18:51.889
But this year, there was almost no artists from overseas

0:18:51.889,0:18:53.961
It was a quiet event

0:18:53.961,0:18:59.908
But I found an excellent exhibit

0:18:59.908,0:19:06.090
Future Lab also produces exhibits for the Ars Electronica Center

0:19:06.090,0:19:11.328
In this video you can see 11 monitors in front of you

0:19:11.328,0:19:16.303
In these monitors you can see the hidden layers of DNN

0:19:16.303,0:19:21.096
As you know, there are many layers behind the deep neural network

0:19:21.096,0:19:25.986
And this exhibit shows the mechanism of the DNN very well

0:19:25.986,0:19:33.589
In detail, they use the CNN (Convolutional Neural Network) with the VGG16 network

0:19:33.589,0:19:37.663
I think this is a simple idea but effective

0:19:37.663,0:19:43.521
By showing the layers all at once, we can see how the DNN works

0:19:43.521,0:19:52.523
I had a chance to interview Hideaki Ogawa, the co-director of the Future Lab

0:19:52.523,0:19:55.696
I was impressed by his words,

0:19:55.696,0:19:59.230
Just as water comes out when you twist the tap

0:19:59.230,0:20:04.022
The future comes out when you type "twist the tap" at the Ars Electronica Center

0:20:04.022,0:20:09.216
He is also an artist still creating their artworks

0:20:09.216,0:20:17.751
Events like this Ars Electronica are now taking place in other cities

0:20:17.751,0:20:24.036
In Paris, there is a similar event called the Némo Biennale

0:20:24.036,0:20:30.462
They held the event at Centquatre and various other locations in Paris

0:20:30.462,0:20:35.026
They designed this event to connect science and art

0:20:35.026,0:20:43.612
I participated in this event and I felt that the direction was so close to the Ars Electronica Festival

0:20:43.612,0:20:49.538
And there are events called Maker Faire

0:20:49.538,0:20:54.205
where people who like to make things gather and show their creations

0:20:54.205,0:21:00.806
The maker faire events are all over the world, and the Nantes Maker Campus was outstanding quality

0:21:00.806,0:21:07.675
And also, I am a director of Tsukuba Mini Maker faire

0:21:07.675,0:21:14.462
Then I met several artists and interviewed them

0:21:14.462,0:21:20.042
First let me introduce "La Machine"

0:21:20.042,0:21:22.793
The moving giant elephant of Nantes

0:21:22.793,0:21:30.000
In the city of Nantes, big elephant carried a lot of people around the city everyday

0:21:30.000,0:21:35.925
And I had a chance to interview the artistic director Mr. Francois Delaroziere

0:21:35.925,0:21:44.080
And according to him, it is important to have such huge artwork moving around the public open city and open space

0:21:44.080,0:21:48.897
And I felt that this is loved by the citizens very much

0:21:48.897,0:21:56.193
From Francois Delaroziere

0:21:56.193,0:22:00.714
I was particularly interested in his focus on movement

0:22:00.714,0:22:08.907
And according to him, movement is a language (of) a machine, and a mechanical organisms

0:22:08.907,0:22:14.380
The next artist is Scott Eaton

0:22:14.380,0:22:17.408
The picture on the left is a finished painting

0:22:17.408,0:22:23.056
The video on the right side shows how he is drawing it

0:22:23.056,0:22:28.550
As you can see, it is just a simple sketch with an outline

0:22:28.550,0:22:33.576
But the AI automatically drew the content with human body

0:22:33.576,0:22:37.505
Scott Eaton has a background in art

0:22:37.505,0:22:41.292
and he also graduated from the MIT media lab

0:22:41.292,0:22:43.964
so he is very good at computer science

0:22:43.964,0:22:50.325
And he studied drawing and sculpture in Florence in Italy

0:22:50.325,0:22:55.229
I think his paintings are under the influence of Michelangelo

0:22:55.229,0:23:02.934
I had the opportunity to interview him, and it was fascinating

0:23:02.934,0:23:08.688
I think he has a great philosophy as an artist who uses AI

0:23:08.688,0:23:12.245
In particular I would like to emphasize the word

0:23:12.245,0:23:15.740
"For an artist, failure is sometimes beautiful"

0:23:15.740,0:23:20.566
I think this is a natural appeal of media art

0:23:20.566,0:23:24.231
Creating art through repeated experimentations

0:23:24.231,0:23:29.416
Next up is Fernado Magalhães

0:23:29.416,0:23:34.229
As you can see, he created a computer graphics image

0:23:34.229,0:23:36.677
that looks like Japanese superheroes

0:23:36.677,0:23:41.029
He didn't make these images by hand

0:23:41.029,0:23:44.655
But he designed an algorithm to create superheroes

0:23:44.655,0:23:52.793
Based on that algorithm the program generates countless superhero's shapes automatically

0:23:52.793,0:23:57.688
This kind of art is what we call "Generative Art"
WHY and How did you create the hero?

0:23:57.688,0:24:01.596
I interviewed him also

0:24:01.596,0:24:04.654
He was born in São Paulo Brazil

0:24:04.654,0:24:07.830
and watched Japanese TV programs in childhood

0:24:07.830,0:24:13.010
So it was there that he came in contact with Japanese culture

0:24:13.010,0:24:15.793
and begin to create these kinds of works

0:24:15.793,0:24:24.576
So I would like to explain what I have learned from these experiences

0:24:24.576,0:24:31.982
First of all I would like to say that I have (never) been to more places

0:24:31.982,0:24:36.618
One that most impressed me was Grotte Chauvet

0:24:36.618,0:24:46.240
This Grotte Chauvet is a cave mural that exists about 36 thousand years old

0:24:46.240,0:24:52.613
Lascaux cave is 20 thousand years old

0:24:52.613,0:24:55.962
So this is probably the oldest cave mural

0:24:55.962,0:25:02.484
We see here a replica of Grotte Chauvet called Grotte Chauvet 2

0:25:02.484,0:25:06.227
Although it is a replica it is so realistic

0:25:06.227,0:25:09.764
It looks like (the) real thing is here

0:25:09.764,0:25:15.061
Here is a mural of lions, but it exists within the same reality

0:25:15.061,0:25:17.605
I was very impressed by this

0:25:17.605,0:25:28.150
And before I came to France, I thought that this "Europe" was a place where the modern western culture has developed

0:25:28.150,0:25:30.312
But that was not the case

0:25:30.312,0:25:36.975
I mean the coast of Mediterranean sea is where civilization begun

0:25:36.975,0:25:40.385
I was finally able to understand this

0:25:40.385,0:25:48.363
Then what force drives the progress of civilization?

0:25:48.363,0:25:55.170
The science fiction novelist Neal Stephenson invented the term "Metaverse"

0:25:55.170,0:25:57.523
in his novel Snow Crash

0:25:57.523,0:26:03.884
In this book, he says that there are some layers of languages

0:26:03.884,0:26:09.500
And the civilization progress is through the power of crossing between these layers

0:26:09.500,0:26:16.155
In his word, "Code" or programming language, is a latest language layer

0:26:16.155,0:26:21.504
A language defines our thinking

0:26:21.504,0:26:27.716
It is difficult to share a concept that has not yet been put into words

0:26:27.716,0:26:30.164
Please imagine this:

0:26:30.164,0:26:37.500
How would you tell yourself in 2019 what was the changes brought by Covid-19

0:26:37.500,0:26:43.422
I think you will find it a bit difficult

0:26:43.422,0:26:49.311
Once a common language is established, sharing concepts becomes possible

0:26:49.311,0:26:57.921
And the role of human in a society is dictated by the measure of technological changes

0:26:57.921,0:27:02.810
The industrial revolution was governed by natural laws

0:27:02.810,0:27:07.410
In particular, how to control engines was very important

0:27:07.410,0:27:14.711
Locomotive automobiles, looms, and letter presses are all powered by engines

0:27:14.711,0:27:21.503
Please remember that the term "engineering" comes from engine

0:27:21.503,0:27:27.897
On the other hand, the IT revolution is governed by language

0:27:27.897,0:27:35.757
So when we can express it in a language, we can execute it

0:27:35.757,0:27:40.739
For example, we often compare a hacker to a wizard

0:27:40.739,0:27:45.292
When a wizard casts a spell, it becomes true

0:27:45.292,0:27:50.532
In this situation, "the spell" means a programming language

0:27:50.532,0:27:59.040
And next, let's consider the AI revolution that is taking place

0:27:59.040,0:28:03.694
I believe that AI is governed by imagination

0:28:03.694,0:28:08.678
In AI, everything exists in a probabilistic way

0:28:08.678,0:28:13.702
There is not rigid distinction between 0 or 1

0:28:13.702,0:28:20.032
From my point of view, this is closer to painting than language

0:28:20.032,0:28:26.373
I mean, In other words, what can be visualized can be executed

0:28:26.373,0:28:37.743
I remind Scott Eaton's statement that "The artist controls the AI with his imagination and ideas" is a perfect example of this

0:28:37.743,0:28:41.753
So I would like to return to the research question

0:28:41.753,0:28:44.783
What is the role of art in advanced technology

0:28:44.783,0:28:49.122
My findings are to be a source of imaginations

0:28:49.122,0:28:53.938
and expands the possibilities to advance the technology

0:28:53.938,0:28:58.008
So I would like to end my presentation

0:28:58.008,0:28:59.934
And thank you very much

0:29:09.297,0:29:12.888
Then

0:29:12.888,0:29:17.862
Can I go progress?

0:29:17.862,0:29:24.625
Yes please, I will give you the floor to organize the round table thank you very much!

0:29:24.625,0:29:26.068
There will be

0:29:26.068,0:29:27.867
I think there will be many questions

0:29:27.867,0:29:31.503
And congratulations of course though on your talk

0:29:31.503,0:29:38.249
But I think in order to have a good discussion it's good to move to the round table

0:29:38.249,0:29:41.801
and then to have the discussion

0:29:41.801,0:29:43.942
Okay thank you very much

0:29:43.942,0:29:47.880
Then let's start the session one

0:29:47.880,0:29:53.400
So in session one we have a presentation from *Attos(?)* first

0:29:53.400,0:29:58.200
Then we will have a presentation from Nao Tokui from Keio University

0:29:58.200,0:30:02.765
Tokui-sensei, could you please start your presentation?

0:30:02.765,0:30:07.877
Hi, yes, thank you!

0:30:07.877,0:30:10.552
(in Japanese) Kikoemasuka? Do you hear me?

0:30:10.552,0:30:13.114
Uh yes, clearly!

0:30:13.114,0:30:14.370
Thank you very much

0:30:14.370,0:30:19.323
Okay so, hi everyone

0:30:19.323,0:30:21.673
Bonjour, thank you for having me

0:30:21.673,0:30:24.441
So let me start my presentation

0:30:24.441,0:30:27.972
So can I share my screen?

0:30:48.654,0:30:53.339
Normally, you can share, you have the right to share that

0:30:53.339,0:30:55.954
yes

0:30:55.954,0:30:58.045
Okay, thanks!

0:30:58.045,0:31:02.122
So today I will talk about AI and creativity

0:31:02.122,0:31:05.471
And before that let me introduce myself

0:31:05.471,0:31:07.530
So my name is Nao Tokui

0:31:07.530,0:31:10.525
I'm an artist and researcher

0:31:10.525,0:31:19.650
And also I'm a founder and CEO of Tokyo based art collective Qosmo

0:31:19.650,0:31:24.470
And I also organized

0:31:24.470,0:31:31.095
computational creativity laboratory at Keio University in Japan

0:31:31.095,0:31:35.509
So today, I want to talk about

0:31:35.509,0:31:37.208
AI and creativity

0:31:37.208,0:31:41.806
And Especially the main theme of my talk is this:

0:31:41.806,0:31:46.187
Is AI capable of creating something new and original?

0:31:46.187,0:31:55.732
Maybe more precisely: Is AI capable of helping us create something new and original

0:31:55.732,0:32:00.751
rather than imitating what we humans have already created

0:32:00.751,0:32:07.613
So why I got interested in this topic

0:32:07.613,0:32:10.402
Is this,

0:32:10.402,0:32:15.548
I entered the University of Tokyo in 1995

0:32:15.548,0:32:22.972
And joined the laboratory, I mean the AI laboratory in 1998

0:32:22.972,0:32:28.322
And also at the same time, I started DJ'ing myself

0:32:28.322,0:32:32.969
And I got kind of obsessed with music

0:32:32.969,0:32:43.032
And I started thinking like "I want to create music, I want to create new music nobody ever listened to"

0:32:43.032,0:32:44.205
so

0:32:44.205,0:32:47.949
But I don't play any musical instruments

0:32:47.949,0:32:51.716
and I don't barely read musical scores

0:32:51.716,0:32:54.299
so how can I make interesting music

0:32:54.299,0:32:59.134
so naturally I turned to programming and AI

0:32:59.134,0:33:08.031
So here, I'm not interested in optimizing and streamlining the music making process

0:33:08.031,0:33:14.084
to make more hit songs more economically

0:33:14.084,0:33:19.385
Rather, instead, I'm interested in

0:33:19.385,0:33:23.718
diversification and deviation

0:33:23.718,0:33:30.359
so how can I make something unique music,

0:33:30.359,0:33:37.694
you know basically a new music

0:33:37.694,0:33:44.973
And here I have an agenda of my talk today

0:33:44.973,0:33:49.543
So I want to talk about three topics

0:33:49.543,0:33:55.257
And first one is "Misusable" AI tools

0:33:55.257,0:34:02.356
The importance of music tools you can misuse

0:34:02.356,0:34:15.300
And you may find it a little bit strange to use the word "misuse" in the discussion of AI

0:34:15.300,0:34:23.600
But when you look back the history of music and other creative fields

0:34:23.600,0:34:33.624
you may realize that it is in fact a history of misuse and misappropriated new technologies

0:34:33.624,0:34:46.898
So one of the recurring patterns is when an artist use new technologies in a way the original inventor didn't intend or imagine

0:34:46.898,0:34:51.258
It is when new form of expression emerge

0:34:51.258,0:34:59.588
So the prime example of these misused technology is for example

0:34:59.588,0:35:03.861
turn table and samplers

0:35:03.861,0:35:11.133
So as for turn tables, you are not supposed to touch and move the vinyl record right?

0:35:11.133,0:35:21.394
And samplers were invented to imitate expensive physical instruments such as pianos and violins

0:35:21.394,0:35:30.397
But the inventor didn't expect users to appropriate and sample somebody else's records and musics

0:35:30.397,0:35:35.196
Such as Funky Drummers or Aiming Brakes or whatever

0:35:35.196,0:35:44.341
And when we think about the current status of AI music tools

0:35:44.341,0:35:47.235
or AI creative tools in general

0:35:47.235,0:35:55.900
You see both extreme ends of spectrum here

0:35:55.900,0:36:06.811
On one hand, you have programmer oriented tools

0:36:06.811,0:36:16.017
like, so you need to install Python and Tensor Flow and you need CUDA of course

0:36:16.017,0:36:24.367
And you know, you need to get used to these tools to make something unique or something new

0:36:24.367,0:36:34.364
And I'm sure some artists can learn and train themselves to get used to these tools

0:36:34.364,0:36:37.930
but usually it's not the case

0:36:37.930,0:36:43.855
And at the other end of the spectrum, we have

0:36:43.855,0:36:49.085
very well-packaged tools, AI tools

0:36:49.085,0:37:00.000
So with one click you can generate a music or with one click the AI can edit your photo, or images, you know

0:37:00.000,0:37:05.370
And in some cases, that's good

0:37:05.370,0:37:09.955
But I think if the tool is too well packaged

0:37:09.955,0:37:21.539
then you cannot "misuse" or you cannot use these tools in your own way, or in your own creative way

0:37:21.539,0:37:32.405
So I think we need something in between these two ends of the spectrum

0:37:32.405,0:37:36.823
And I call it "Misusable" AI tools

0:37:36.823,0:37:47.791
And following this principal, I created a simple AI tool for musicians

0:37:47.791,0:37:57.645
And it is on Ableton Live, a famous digital audio workstation software

0:37:57.645,0:38:06.847
And yeah, so this is an Ableton Live plugin

0:38:06.847,0:38:15.618
And what it does is it allows you as artist to train your own AI model

0:38:15.618,0:38:22.697
within this software, so you don't have to deal with Python and CUDA

0:38:22.697,0:38:30.658
So only thing you need to do is just collect music data, in this case MIDI files

0:38:30.658,0:38:33.875
and drag and drop on this device

0:38:33.875,0:38:47.169
And voila, you got a trained model on this device, and you can generate new rhythms continuously

0:38:47.169,0:38:49.770
And you can:

0:38:49.770,0:38:51.396
♫sick beats♫

0:38:51.396,0:38:53.472
I hope you can hear the audio

0:38:53.472,0:39:04.476
♫sick beats♫

0:39:04.476,0:39:09.927
And a good thing about this tool is that you can actually "misuse" this tool

0:39:09.927,0:39:15.209
So you can train your model with very obscure data sets

0:39:15.209,0:39:28.033
or, I don't know, this device is meant for rhythm generation, but you can train your own model with a melody data, for example

0:39:28.033,0:39:32.715
and see what comes out

0:39:32.715,0:39:39.737
Okay, that's one small project I did in 2020

0:39:39.737,0:39:45.598
And I want to talk about the second topic here

0:39:45.598,0:39:52.214
Which is embracing the uncertainty or errors AI brings

0:39:52.214,0:40:05.527
So this is a visualization of the output of the same model I just introduced

0:40:05.527,0:40:14.230
And this is useful and great, and also you can misuse this tools to generate something unique

0:40:14.230,0:40:18.632
But still you need your own training data to train this model

0:40:18.632,0:40:28.117
And mainly you can say like this model is still imitating human creation with AI, right?

0:40:28.117,0:40:36.470
So in 2017 I created something called "Neural Beatbox"

0:40:36.470,0:40:41.963
So what I did is to combine rhythm generation model, the same rhythm generation model,

0:40:41.963,0:40:45.481
with a sound classification model

0:40:45.481,0:40:55.992
And you can play this neural beatbox on this website neuralbeatbox.net

0:40:55.992,0:40:59.760
so if you're interested please take a look

0:40:59.760,0:41:09.080
what I did was to integrate the sound classification model with the rhythm generation model

0:41:09.080,0:41:16.180
And generated rhythm pattern will be played

0:41:16.180,0:41:20.946
with the instant drum kit

0:41:20.946,0:41:25.743
the sound classification model created out of the recorded sound materials

0:41:25.743,0:41:29.360
♫beatbox♫

0:41:29.360,0:41:36.033
So we created this website during the Covid lockdown

0:41:36.033,0:41:48.490
on this website you create your own beat with the help of AI and you can share your sessions with your friends

0:41:48.490,0:41:55.557
So that you can join your instant beatbox session

0:41:55.557,0:42:03.782
And I should mention that sound classification is not perfect of course

0:42:03.782,0:42:06.858
but that's what we wanted

0:42:06.858,0:42:17.283
We wanted to deviate from what humans have created

0:42:17.283,0:42:30.142
♫sick session♫

0:42:30.142,0:42:34.450
Okay ,so what I just said is like this

0:42:34.450,0:42:43.569
so when you try to create something new and unique you want to deviate and branch out from the conventions or common senses

0:42:43.569,0:42:49.134
And we hope it will be a manifestation of creativity, but sometimes,

0:42:49.134,0:43:03.739
Especially from a conventional perspective, these deviation can be just a mistake or an error, right?

0:43:03.739,0:43:10.157
So we need to know how to embrace the mistakes

0:43:10.157,0:43:27.073
And you have to know how to differentiate mistakes from, you know, a manifestation of creativity

0:43:27.073,0:43:41.723
And this error and creativity is one of my main theme I think

0:43:41.723,0:43:49.476
So the other project where I embrace the uncertainty of AI is this AI DJ project

0:43:49.476,0:43:54.277
It's a back-to-back DJ session with me

0:43:54.277,0:43:59.898
and AI DJ

0:43:59.898,0:44:09.995
and AI DJ selects and plays sometimes unexpected songs

0:44:09.995,0:44:14.678
But this uncertainty leads to very interesting DJ performance

0:44:14.678,0:44:28.573
So sometimes the AI selects something I didn't expect or I couldn't imagine

0:44:28.573,0:44:41.733
But this unexpectedness was so interesting as a DJ

0:44:41.733,0:44:54.507
And we are so fortunate to have opportunities to play at various locations including Google I/O in San Francisco

0:44:54.507,0:44:57.568
and Scopitone festival in Nantes

0:44:57.568,0:45:13.599
So we extended this scene and we turned it into a real-time AI jam session

0:45:13.599,0:45:24.801
♫sick jam session♫

0:45:24.801,0:45:34.878
I hope you can listen to and hear the audio now

0:45:34.878,0:45:38.587
(In Japanese) Daijoubukana?

0:45:38.587,0:45:47.051
Anyway, so instead of letting AI to select existing music

0:45:47.051,0:45:54.122
We made an AI system that makes music on stage in real time

0:45:54.122,0:45:59.361
So in this performance, three AI models, namely

0:45:59.361,0:46:08.455
rhythm generation model, baseline generation, and loop selection interact with each other

0:46:08.455,0:46:11.404
And keep improvising a dance track

0:46:11.404,0:46:19.898
So I as a DJ intervene the processor by manipulating mixer and adding a sound in the turn table

0:46:19.898,0:46:28.676
So it's not a disk jockey anymore, it's more like a machine jockey or an AI jockey

0:46:28.676,0:46:38.248
Okay, so finally I want to talk about this, pushing AI to the edge

0:46:38.248,0:46:45.788
And so let's get back to the original question: Is AI capable of creating something new and original

0:46:45.788,0:46:52.780
So here I want to talk about Generative Adversarial Network

0:46:52.780,0:46:58.212
So it's a famous framework so I'm not going to explain it in detail

0:46:58.212,0:47:07.626
But it's so famous for the capability of generating very realistic faces

0:47:07.626,0:47:12.994
But here, I want to use it for, again rhythm patterns

0:47:12.994,0:47:24.756
And in this model I added a conditioning input

0:47:24.756,0:47:32.428
so you can specify the genre, and generate patterns

0:47:32.428,0:47:41.770
silence

0:47:41.770,0:47:47.000
do you hear the audio? I cannot hear

0:47:47.000,0:47:49.715
Uh I cannot hear

0:47:49.715,0:47:51.647
somehow

0:47:51.647,0:47:53.789
Good? No?

0:47:53.789,0:47:55.619
No

0:47:55.619,0:48:18.696
deafening silence

0:48:18.696,0:48:24.863
Sorry, do it again

0:48:24.863,0:48:28.057
drum plays for a second

0:48:28.057,0:48:30.242
Okay

0:48:30.242,0:48:38.615
silence

0:48:38.615,0:48:49.815
So again, I added a conditional input so that you can specify the genre of the generated rhythm patterns

0:48:49.815,0:48:58.019
But it's not interesting, so I added another discriminator to this model

0:48:58.019,0:49:13.192
I added another discriminator that is for classifying the genre of the generated rhythms

0:49:13.192,0:49:20.935
So the generator is trained to confuse the additional discriminator as well

0:49:20.935,0:49:32.940
so that it can generate realistic rhythm patterns that don't belong to any genres in the training data set

0:49:32.940,0:49:37.060
So this is the result

0:49:37.060,0:49:42.523
sick beat ensues

0:49:42.523,0:49:47.547
I hope you can hear, I don't I can hear (Yes we can, and it's awesome!)

0:49:47.547,0:49:50.350
(In Japanese) Daijoobudesuka?

0:49:50.350,0:50:07.742
sick hit-hat beats

0:50:07.742,0:50:19.989
So here, I wanted to realize the tag of war between conventions and deviations

0:50:19.989,0:50:30.084
So now AI is trying to tell which deviation is good and interesting

0:50:30.084,0:50:36.498
And this is I believe what human artists do actually

0:50:36.498,0:50:44.334
And finally I want to introduce one of my favorite quotes of Scott Adams

0:50:44.334,0:50:52.060
He's a famous comic writer of Dilbert comic strip

0:50:52.060,0:51:00.000
And it goes like this: Creativity is allowing yourself to make mistakes. Art is knowing which ones to keep

0:51:00.000,0:51:10.937
And in the context of AI and creativity I think AI is a tool that helps you make interesting, meaningful, and amusing mistakes

0:51:10.937,0:51:17.239
And consequently, it helps you to create something new and original

0:51:17.239,0:51:26.457
Okay, finally as Eto-san introduced, I published this book last year

0:51:26.457,0:51:36.966
And I'm working on English translation, and hopefully I can deliver it within a few months

0:51:36.966,0:51:42.124
Okay, so thank you so much!

0:51:42.124,0:51:49.503
Thank you very much Tokui-sensei, I loved the presentation very much

0:51:49.503,0:51:51.458
I'm sorry about the audio trouble

0:51:51.458,0:51:57.883
No no, no problem, I have so much questions for Professor Tokui

0:51:57.883,0:52:06.521
But on this program, I will do the presentation for session one and all

0:52:06.521,0:52:10.099
Then we'll have a 10 minutes Q and A

0:52:10.099,0:52:14.944
So I would like to do this and to next presenter

0:52:15.000,0:52:22.396
So next presenter from IRCAM Professor Gerard Assayag

0:52:22.396,0:52:26.440
Assayag-sensei, can you hear me?

0:52:26.440,0:52:27.351
Yes, yes.

0:52:27.351,0:52:35.361
Okay, thank you very much for accepting the offer to be a speaker of this lecture.

0:52:35.361,0:52:39.340
Could you please start your presentation as I can say?

0:52:39.340,0:52:39.840
Okay.

0:52:43.520,0:52:45.840
Here you are.

0:52:48.160,0:52:49.053
Can you see it?

0:52:49.053,0:52:49.765
Yes.

0:52:49.765,0:52:52.878
Perfect all right so,

0:52:52.878,0:53:01.922
My presentation will be about my ERC European Research Council advanced grant REACH:

0:53:01.922,0:53:07.276
Raising co-creativity in Cyber-Human Musicianship

0:53:07.276,0:53:09.846
First of all let me present IRCAM,

0:53:09.846,0:53:12.097
the place where I am a researcher

0:53:12.097,0:53:15.718
So IRCAM is the institute where we research the coordination of acoustic music,

0:53:15.718,0:53:18.812
which is actually a part of Centre Georges Pompidou in Paris.

0:53:18.812,0:53:26.603
It was created by famous conductor and composer Pierre Boulez in the 70s when the when the Centre Pompidou was created.

0:53:26.603,0:53:32.866
And it is the the music and sound research parts of Centre Pompidou.

0:53:32.866,0:53:38.518
So we have a three part in IRCAM,

0:53:38.518,0:53:42.394
a research lab called Science and Technology of Sound and Music (STMS),

0:53:42.394,0:53:50.320
who is operated by CNRS and Sorbonne University and IRCAM of course, and the Minister of the Culture Communication.

0:53:50.320,0:53:52.960
We have a music creation department

0:53:54.000,0:53:58.967
with concert halls and composers in residence.

0:53:58.967,0:54:01.111
And music commissions etc.

0:54:01.111,0:54:06.853
And we have an education department where we have a master's program 
first for young scientists,

0:54:06.853,0:54:11.103
and another program in technology for musicians.

0:54:11.103,0:54:14.480
So it's a very original model of innovation and creativity

0:54:15.280,0:54:21.040
where we have artists that are immersed into a research context.

0:54:23.360,0:54:30.033
All right, so in IRCAM I have created a team called Music Representation team years ago,

0:54:30.033,0:54:34.937
and now it has become the biggest team in IRCAM.

0:54:34.937,0:54:41.157
And we have a lot of researchers on AI and creativity for artistic purposes

0:54:41.157,0:54:42.182
specifically music.

0:54:42.182,0:54:45.376
So we have five poles in this team,

0:54:45.376,0:54:48.926
so certain of these poles are concerned with

0:54:48.926,0:54:54.992
music, composition formalization, and formal approaches to music.

0:54:54.992,0:55:00.210
But we have the three poles here are really concerned with artificial intelligence.

0:55:00.210,0:55:04.709
So REACH is really the project that I will be speaking about.

0:55:04.709,0:55:14.009
ACIDS is a project that is highly oriented towards the machine learning for creative applications.

0:55:14.009,0:55:21.760
And activities is really oriented towards the idea of time, and how you write and control the time in an interactive setup.

0:55:23.840,0:55:30.320
So to give an example, here is a program that I wrote many years ago,

0:55:31.040,0:55:37.007
and has now become the standard all over the world for a computer-assisted composition.

0:55:37.007,0:55:38.504
It's called open music,

0:55:38.504,0:55:40.436
and we have published three books where

0:55:40.436,0:55:46.803
thousands of composers explain how they would use open music to create new music.

0:55:46.803,0:55:51.378
So open music is actually a programming language but it is a visual programming language.

0:55:51.378,0:55:59.555
So composers learn how to program more easily because it's totally visual and they can design new musical application.

0:55:59.555,0:56:03.400
So this is not the artificial intelligence approach, this is the formal approaches,

0:56:03.400,0:56:10.708
where composers actually have to specify the algorithm that they want to use in order to create music.

0:56:10.708,0:56:14.320
After having created open music with of course with my team,

0:56:15.280,0:56:20.160
I have moved to the idea of creating intelligent interaction with agents.

0:56:20.160,0:56:24.638
With creative agents so we are moving closer to artificial intelligence.

0:56:24.638,0:56:29.145
And again quite a number of years ago, I created with colleagues

0:56:29.145,0:56:32.893
the OMax paradigm of intelligent interaction.

0:56:32.893,0:56:38.049
So you see OMax is really the simple idea that you have intelligent agent

0:56:38.049,0:56:44.576
feed with AI that are able to listen to music either in offline or in real time,

0:56:44.576,0:56:47.420
that are able simultaneously to learn.

0:56:47.420,0:56:52.213
So apply a machine learning model create a model, so a mirror of musical memory,

0:56:52.213,0:56:59.751
simultaneously scan and navigate the memory in order to generate new materials

0:56:59.751,0:57:02.734
and propose this new materials to the musician.

0:57:02.734,0:57:04.253
And then you have reaction,

0:57:04.253,0:57:10.484
reactions on both sides, the musician will react to the AI, the AI will react to the musician.

0:57:10.484,0:57:12.712
And we have this creative loop.

0:57:12.712,0:57:16.615
So OMax had a lot of hairs and descendants,

0:57:16.615,0:57:23.215
and you see many popular systems that have been derived from or original researches

0:57:23.215,0:57:25.056
on the OMax paradigm.

0:57:25.056,0:57:33.223
And notably all the work that is done right now at Sony Music and now at Spotify is

0:57:33.223,0:57:39.120
(and also the) work done by François Pachet,

0:57:39.120,0:57:45.966
was immediately derived from our original research work at OMax.

0:57:45.966,0:57:48.505
So OMax has become a very important paradigm,

0:57:48.505,0:57:55.529
and we have moved from this paradigm to something even more interesting right now.

0:57:55.529,0:58:02.151
But let me just give you an idea of what this interaction paradigm is about.

0:58:02.151,0:58:05.967
So before learning, the system must listen.

0:58:05.967,0:58:10.560
So you must have a perception aware system of listening.

0:58:10.560,0:58:13.844
We call this machine or artificial listening,

0:58:13.844,0:58:19.410
so that we're gonna we're gonna segment the stream of music into

0:58:19.410,0:58:26.208
musical in it that will be distributed over some mathematical structure or maybe a geometry,

0:58:26.208,0:58:32.081
and we will discover with cognitive algorithm a symbolic alphabet structure.

0:58:32.081,0:58:39.284
Even though we are dealing with audio, we will discover a symbolic alphabet structure of on the musical unit

0:58:39.284,0:58:41.144
that will deliver a symbolic stream.

0:58:41.144,0:58:44.280
So from the symbolic stream we will learn a model.

0:58:44.280,0:58:46.880
So we will use a number of machine learning algorithm

0:58:46.880,0:58:50.092
and then regenerate and render new sequences.

0:58:50.092,0:58:54.523
And the three processes listen, learn, and generate, are real time and concurrent

0:58:54.523,0:59:02.293
and they are both concurrent and cooperative.

0:59:02.293,0:59:08.988
So the nice drawing that you see here is the visual representation of a musical sequence

0:59:08.988,0:59:11.050
that has been learned in real time by OMax.

0:59:11.050,0:59:20.473
And all the colored arcs that you see are actually connecting different places of the music with regard to similarity.

0:59:20.473,0:59:24.560
So because we have this connection created by the AI,

0:59:25.680,0:59:29.392
we have a kind of cartography of a map of the music.

0:59:29.392,0:59:38.201
And the system just have to navigate around this map to create new sequences that will be statistically coherent with the material that was learned,

0:59:38.201,0:59:40.253
but still creative and novel.

0:59:40.253,0:59:47.026
So you see here in this model you have the musician who is for instance improvising,

0:59:47.026,0:59:48.195
and there is a double loop.

0:59:48.195,0:59:55.302
He's listening to other musicians and but he's also, he or she, listening to to themselves,

0:59:55.302,0:59:58.228
and also listening to its sound memories.

0:59:58.228,1:00:00.564
So himself or herself in the past.

1:00:00.564,1:00:07.638
And the memory is a virtual part because it is constituted by all that the musician has played,

1:00:07.638,1:00:09.827
all that the other musicians are playing,

1:00:09.827,1:00:14.354
and all that the musician has ever played or learned in his life. So this is all virtual.

1:00:14.354,1:00:19.360
And this is exactly the musical memory that the AI system is simulating.

1:00:27.360,1:00:31.309
I'm hearing some music coming from somewhere.

1:00:31.309,1:00:32.055
Okay, okay okay.

1:00:32.055,1:00:38.855
Okay, so somax is like you know, this zero point here in this graph that represent two dimensions

1:00:38.855,1:00:46.602
where you have the reactive dimension the system reacts instantly to a musician.

1:00:46.602,1:00:54.947
and the planning dimension where the the user can actually plan behaviors like compose for instance 
a harmonic grid or any composition

1:00:54.947,1:00:58.491
so OMax is really at zero because it is not really planning

1:00:58.491,1:01:01.761
and it is not reactive but it has a lot of machine learning

1:01:01.761,1:01:06.140
so then we have we have developed more intelligent systems, like a smart system

1:01:06.140,1:01:11.212
where we have a high level of reactivity

1:01:11.212,1:01:15.319
we have developed the important system where we have a high level of planning

1:01:15.319,1:01:20.110
and now we are working 
on a hybrid system where we would have a good compromise

1:01:20.110,1:01:23.294
between being totally reactive to what the live musicians are doing

1:01:23.294,1:01:32.560
and also having some planning and being able to develop interesting 
and sophisticated and structured musical processes

1:01:33.360,1:01:41.680
so here is the the general diagram the that we are now exploring in the REACH project

1:01:43.200,1:01:45.544
where you have some musical input musical signal

1:01:45.544,1:01:51.772
you have a machine listening unit that creates a symbolic signal stream

1:01:51.772,1:01:58.772
you have a learning unit that will do some machine learning, statistical, probabilistic, or deep learning

1:01:58.772,1:02:05.772
that will learn a model and that will give back some information 
to the listening machine

1:02:05.772,1:02:10.927
so it will help the listening machine to improve itself

1:02:10.927,1:02:12.960
so the learning will create a memory model

1:02:14.000,1:02:17.887
where we will have an interaction agent

1:02:17.887,1:02:22.861
that will query the model in order to create new musical material

1:02:22.861,1:02:26.747
but that will still be listening to the 
musical stream in the input

1:02:26.747,1:02:32.878
so the interacting agent will be able also to be reactive and not 
only creative and generative

1:02:32.878,1:02:38.860
and the user will be able to specify scenarios so to compose some 
music

1:02:38.860,1:02:44.937
but then the interacting model will be able to give feedback control to the scenario unit

1:02:44.937,1:02:51.977
in order to be able to generate artificial scenarios that will be interacting with the user in general

1:02:51.977,1:02:58.089
so this is a highly sophisticated architecture that will be able to generate very interesting 
musical experiments

1:02:58.089,1:03:02.717
so now let me show you just two-minute video

1:03:02.717,1:03:07.872
where you will see some example or where we have reached so far

1:03:07.872,1:03:10.562
you will see a pianist playing

1:03:10.562,1:03:15.333
and at some point you will hear three singers Edith Piaf Elisabeth Schwarzkopf

1:03:15.333,1:03:18.092
and Billie Holiday who are very famous singers

1:03:18.092,1:03:20.201
so we have used audio archives

1:03:20.201,1:03:25.888
but the AI which will totally re-improvise the audio archives

1:03:25.888,1:03:29.840
in order to align the improvisation with what the pianist is doing

1:03:29.840,1:03:44.159
♫Pianist playing♫

1:03:44.159,1:04:26.822
♫The AI starts improvising in real time♫

1:04:26.822,1:05:32.840
♫Epic collaboration between the pianist and the AI♫

1:05:34.400,1:05:35.840
oh sorry

1:05:38.161,1:05:43.079
♫Brief playback♫

1:05:46.744,1:06:30.960
♫Epic human-AI jam♫

1:06:30.960,1:06:33.461
okay so you have seen two examples

1:06:33.461,1:06:38.825
one was an offline example where the AI has learned a lot of materials from the three singers

1:06:38.825,1:06:44.105
and then is able to recompose and re-improvise in the audio domain

1:06:44.105,1:06:49.193
but as well also in the video domain the music

1:06:49.193,1:06:52.562
and in the last part of the video you have seen a real time example

1:06:52.562,1:06:59.218
where the system captures and learned his model in real time

1:06:59.218,1:07:02.206
from what the musician 
is actually performing

1:07:02.206,1:07:08.398
and is able to instantly interact and have a dialogue with the 
musician

1:07:08.398,1:07:12.508
so every time you were listening to the saxophone sound

1:07:12.508,1:07:15.263
and the musician was obviously not playing his instrument

1:07:15.263,1:07:20.374
it was the AI playing and proposing a dialogue to the to the musician

1:07:20.374,1:07:28.421
okay recently we have begun a national research agency project called MERCI

1:07:28.421,1:07:30.480
Mixed Musical Reality with Creative Insturments

1:07:32.880,1:07:35.203
where we have an industrial partner called HyVibe

1:07:35.203,1:07:42.242
and HyVibe has obtained a lot of awards in the industrial 
world

1:07:42.242,1:07:50.740
for instance there is the challenge award of the best startup for 2021

1:07:50.740,1:07:53.913
and they are designing a active acoustic system

1:07:53.913,1:08:07.851
that where they transform material devices into an acoustic diffusion system

1:08:07.851,1:08:11.116
and they have created they have 
created a new instrument called the HyVibe guitar

1:08:11.116,1:08:16.658
that is equipped with actuators and sensors and computing power inside the guitar

1:08:16.658,1:08:21.618
and where you can, you can have some processing of the sound of the guitar

1:08:21.618,1:08:26.727
that is rendered not by a loudspeaker but by the wooden body of 
the guitar itself

1:08:26.727,1:08:35.481
so it gives the the musician the feeling that the instrument is really reacting to what he's doing

1:08:35.481,1:08:37.840
so here's an example

1:08:37.840,1:08:45.120
♫Creative guitar performance♫

1:08:45.120,1:08:46.446
and another

1:08:46.446,1:08:54.800
♫Creative guitar performance♫

1:08:54.800,1:09:02.183
so so what we want to do is to be able to embed the artificial intelligence into the instrument

1:09:02.183,1:09:07.999
so this instrument is not only capable of extending the sound of the instrumentist

1:09:07.999,1:09:13.466
but also to add an intelligent musical layer to what the musician is 
doing

1:09:13.466,1:09:16.113
and maybe to co-improvise with the musician

1:09:16.113,1:09:18.330
and this is what we call co-creativity

1:09:18.330,1:09:26.394
when we have an interactive situation where a musician and a computer system are able to co-create or co-improvise

1:09:26.394,1:09:32.912
and this is where we get to the 
REACH project that has just begun the last year

1:09:32.912,1:09:39.682
where we are kind of wrapping up and summing up all this big experience

1:09:39.682,1:09:46.506
in writing AI system for interactive music creation

1:09:46.506,1:09:53.685
where we want to really really focus on what I call co-creativity 
between human and AI

1:09:53.685,1:10:00.133
emphasizing that creativity is an emerging dynamics resulting from 
complex interaction between actors

1:10:00.133,1:10:06.106
so it cannot be understood by considering each 
agent's production in separation

1:10:06.106,1:10:13.149
but on the contrary you have to consider really the sum of the behaviors of the agents

1:10:13.149,1:10:22.794
so this frees us from the concept of artificial creativity art artificial intelligence in the art

1:10:22.794,1:10:26.473
because creativity is not a state that 
you are trying to reach

1:10:26.473,1:10:28.880
it's a dynamical effect,

1:10:28.880,1:10:31.956
an emergent effect of interaction in a complex system

1:10:31.956,1:10:39.404
so you can never catch really what creativity or co-creativity is in a static way

1:10:39.404,1:10:42.147
it will only emerge in the time of interaction

1:10:42.147,1:10:45.376
this is the idea that we defined in REACH

1:10:45.376,1:10:52.897
so cyber-human co-creativity will appear when you have emergence of 
cohesive or contrasting joint behaviors

1:10:52.897,1:10:56.658
that you are not able to reduce to individual processes

1:10:56.658,1:11:02.020
and then you will have operation of non-linear regime of event and structure formation

1:11:02.020,1:11:04.468
that will create core evolutions of forms

1:11:04.468,1:11:07.606
and this happens because you have cross-learning processes

1:11:07.606,1:11:10.450
where the machine learns in real time from the musician

1:11:10.450,1:11:12.394
but the musician learns in real time from the machine

1:11:12.394,1:11:17.223
or in general agents that can be artificial or human

1:11:17.223,1:11:22.660
learn from one another in a cross way

1:11:22.660,1:11:28.377
and this will create complex 
feedback loops and reinforcement mechanism

1:11:28.377,1:11:32.432
that will favor the emergent mechanism

1:11:32.432,1:11:38.621
So a cyber physical system like the guitar for 
instance is a cyber physical system

1:11:38.621,1:11:43.100
they create an interaction continuity between digital and 
physical world

1:11:43.100,1:11:47.963
now we want to propose the term cyber audience for systems that create a synergy

1:11:47.963,1:11:52.558
between the digital models and the human mind the human creativity

1:11:52.558,1:11:56.523
so this is the the structure 
of REACH

1:11:56.523,1:12:00.514
but mainly what we have is two central tasks

1:12:00.514,1:12:03.854
that are kind of converging one to the other

1:12:03.854,1:12:09.941
one is to augment the digital agent's abilities with better AI algorithms

1:12:09.941,1:12:13.417
enhance creativity autonomy sensitivity to context

1:12:13.417,1:12:16.477
but also cyber physical extension like the guitar

1:12:16.477,1:12:19.285
so they can act in the material world

1:12:19.285,1:12:24.725
on the other side we will take the human and get it closer to 
the digital agent

1:12:24.725,1:12:30.704
by augmenting the human ability by interfacing them into embedded mixed realities

1:12:30.704,1:12:34.607
so for instance the the creative guitar that we are doing with HyVibe

1:12:34.607,1:12:37.110
is our first mixed reality instrument

1:12:37.110,1:12:46.795
so something that augments the the natural reality by a digital augmentation

1:12:46.795,1:12:49.796
so the REACH artistic impact is huge

1:12:49.796,1:12:55.639
recently we had the concert at the *maison de la jolla(?)* music with 
the *orchest national the jazz(?)*

1:12:55.639,1:13:00.776
and they were playing with our algorithm that were interacting in 
real time with the whole orchestra

1:13:00.776,1:13:03.181
which is more than 20 musicians

1:13:03.181,1:13:09.166
we have issued a new record and a book called "Artist This Year"

1:13:09.166,1:13:13.411
where you can listen to all this interactive concert with AI,

1:13:13.411,1:13:24.839
and you have 200 pages of critical analysis and commentary of the 
phenomenon of AI in art.

1:13:24.839,1:13:33.537
A lot of concerts festivals etc where all systems are actually 
used in real life

1:13:33.537,1:13:39.654
and I will just show a one minute video where you will see the same 
kind of human augmentation

1:13:39.654,1:13:44.211
but here is the video so we use the archive of Dianne Reeves' concert

1:13:44.211,1:13:45.774
at the Monterey Jazz Festival

1:13:45.774,1:13:49.160
and the archives is controlled by the AI in order

1:13:49.160,1:13:52.948
that it's able to 
react in real time to what the pianist is doing

1:13:52.948,1:15:21.200
♫The singer AI is reacting to the pianist♫

1:15:21.200,1:15:24.800
so thank you for your 
attention and I will stop here

1:15:27.840,1:15:30.639
Thank you very much Assayag-sensei

1:15:30.639,1:15:36.592
your presentation is very interesting and deepful (deeply insightful), thank you very much

1:15:36.592,1:15:41.997
and I failed to tell this earlier for our audience

1:15:41.997,1:15:48.259
if you have any questions please post questions to the chat

1:15:48.259,1:15:54.616
We will have Q&A later in this session

1:15:54.616,1:16:03.960
Then next, I would like to welcome Professor Jean-Pierre Merlet from INRIA

1:16:03.960,1:16:08.596
Merlet-sensei, could you please start your presentation?

1:16:08.596,1:16:11.499
Okay do you hear me?

1:16:14.800,1:16:16.720
okay I think you are

1:16:18.720,1:16:20.279
seeing my screen right?

1:16:20.279,1:16:25.805
uh I I'm sorry uh you have to monitor

1:16:25.805,1:16:28.160
yeah that's a problem

1:16:31.360,1:16:33.141
Ah, okay, let me see

1:16:33.141,1:16:37.760
Can you share the window on the left side

1:16:39.840,1:16:48.240
wait a minute I will activate the second screen

1:16:48.240,1:16:54.800
maybe you can share 
not for a monitor for only a window

1:16:58.240,1:17:01.840
oh

1:17:04.640,1:17:05.815
do you see my screen?

1:17:05.815,1:17:07.819
no

1:17:07.819,1:17:11.845
no? not yet

1:17:23.600,1:17:26.480
no you don't see anything?

1:17:26.480,1:17:33.280
and it's coming and maybe we 
can wait for a few seconds and I think it's going to be fine

1:17:33.280,1:17:38.446
sorry for that, I will disconnect my second screen

1:17:53.760,1:17:57.840
I don't know what is happening

1:18:08.320,1:18:11.840
zoom is not really working well for me

1:18:19.760,1:18:27.338
of course you can (you are) okay to share a full monitor, then I think you can

1:18:27.338,1:18:29.338
Yeah but

1:18:33.060,1:18:36.199
is that okay with you do you see my screen now?

1:18:38.560,1:18:40.014
did you see my screen?

1:18:40.014,1:18:41.840
No, I don't think so

1:18:41.840,1:18:44.540
No?

1:18:44.540,1:18:47.219
I don't know what is going on

1:18:49.839,1:18:55.359
I propose maybe you can send 
me your your presentation and I will

1:18:55.359,1:18:57.325
But yeah I have videos so

1:18:57.325,1:18:59.040
Oh you have videos

1:19:01.859,1:19:04.979
I don't understand, stop sharing?

1:19:06.800,1:19:14.320
and I'm really sorry because I have to update 
my zoom and the new one is not working

1:19:17.520,1:19:25.280
application windows okay maybe I can try 
that one and here do you see my screen?

1:19:27.440,1:19:27.940
hello?

1:19:27.940,1:19:30.093
no no no, I mean it's black

1:19:30.093,1:19:31.419
it's black yes

1:19:31.419,1:19:32.724
yeah only black

1:19:32.724,1:19:39.161
it's black? but it's written you started to share your screen

1:19:39.161,1:19:44.495
yeah I think I have a problem with my display system

1:19:44.495,1:19:49.840
I don't know

1:19:54.234,1:19:57.871
Um...

1:19:57.871,1:20:03.840
I don't know what is happening

1:20:20.800,1:20:22.361
so you don't see anything?

1:20:22.361,1:20:24.032
We don't see anything

1:20:24.032,1:20:28.862
I understand you are sharing your screen but we don't see anything

1:20:28.862,1:20:31.733
arriving on the screen actually

1:20:31.733,1:20:35.958
Okay, let's try again

1:20:42.643,1:20:47.379
Urg, I don't understand

1:20:50.240,1:20:55.967
you could hear the monitor for the first time

1:20:55.967,1:20:59.840
so yeah I, this is what I'm doing

1:21:03.600,1:21:05.315
do you see something?

1:21:05.315,1:21:06.766
no

1:21:06.766,1:21:07.360
an hear?

1:21:09.600,1:21:12.418
so you don't see my monitor at all right?

1:21:12.418,1:21:13.840
no

1:21:16.880,1:21:20.218
I'm sorry about that

1:21:23.440,1:21:27.840
I don't see

1:21:28.720,1:21:34.800
I don't understand this usually 
should work except for this problem of

1:21:39.520,1:21:43.440
maybe you can reconnect your 
(your last) your second screen and

1:21:44.800,1:21:46.158
this is what I have done

1:21:46.158,1:21:47.062
okay

1:21:47.062,1:21:47.971
but you don't see,

1:21:47.971,1:21:49.812
Jean-Pierre?

1:21:49.812,1:21:50.800
you don't see anything

1:21:50.800,1:21:51.661
Oui?

1:21:52.000,1:21:59.136
what if you, sorry hello everybody, what if you send your slides via file sender?

1:21:59.136,1:22:00.563
But the problem is that I

1:22:00.563,1:22:02.807
File sender? to download and...

1:22:02.807,1:22:06.067
yeah but the problem is that i 
have movies.

1:22:06.067,1:22:09.840
Ah you have too many yeah okay, sorry

1:22:12.320,1:22:16.800
okay but I will, maybe I can, I don't 
know why you don't see the screen

1:22:18.720,1:22:22.854
you can change the order of a presentation

1:22:22.854,1:22:27.520
for example you can switch Magali-san and Merlet-san

1:22:29.520,1:22:31.600
then we have some..

1:22:31.600,1:22:37.840
yeah but this this will not 
solve the just sharing problem we have

1:22:40.960,1:22:45.000
let me try something, you don't see anything at all right now?

1:22:45.000,1:22:47.879
A black screen or something like that?

1:22:48.320,1:22:49.619
just a black screen

1:22:49.619,1:22:50.599
black screen

1:22:50.599,1:22:57.131
okay so I'm sorry I don't know what 
I can do there

1:22:57.131,1:23:05.947
okay I can send for sure I can't send the presentation but this could be 
a pity because there are a lot of movies going on

1:23:05.947,1:23:11.280
maybe I will, okay you can 
switch I will try to reconnect and

1:23:13.120,1:23:16.000
maybe just try to disconnect and reconnect maybe

1:23:19.440,1:23:20.800
I can try that

1:23:22.701,1:23:23.760
yeah but

1:23:26.720,1:23:31.243
new share, let's try new share

1:23:36.400,1:23:39.001
let's try something else

1:23:39.001,1:23:41.519
you still don't see anything

1:23:41.519,1:23:42.357
no

1:23:42.357,1:23:43.180
right

1:23:45.360,1:23:50.320
and I'm really sorry about 
that I don't know what to do

1:23:53.280,1:23:59.272
this usually works except for this actually appears this morning

1:23:59.272,1:24:01.840
so maybe yes we can

1:24:03.280,1:24:10.640
close the zoom program, the zoom application then connect to zoom

1:24:10.640,1:24:15.840
okay I will do that I will 
disconnect and reconnect again

1:24:27.520,1:24:33.840
so maybe I don't know if someone has a question 
maybe we can take one question

1:24:33.840,1:24:46.080
yeah it's better to use this time to hold Q&A so if 
anyone has a question to audience (from audience)

1:24:53.200,1:25:00.880
Of course if you have question to Professor Tokui and Professor Asayag, and ask them also

1:25:00.880,1:25:04.859
yes, I have a question for Mr. Tokui

1:25:05.760,1:25:09.827
how did you create a GAN (Generative Adversarial Network) for this?

1:25:09.827,1:25:19.935
because I think it's very difficult to create a discriminator for what is a right rhythm and wrong rhythm?

1:25:19.935,1:25:25.840
Or Marlet-san, could you please share?

1:25:32.649,1:25:35.535
(In Japanese) Oh, kitakitakita.

1:25:35.535,1:25:37.542
Marlet-san ok

1:25:39.340,1:25:39.840
it's very good

1:25:44.335,1:25:45.929
(In Japanese) Are? Kikoeta?

1:25:47.600,1:25:53.840
Marlet-san could you please say something

1:25:56.400,1:25:59.647
I can see your sharing monitor,

1:25:59.647,1:26:03.658
and sharing window, but I cannot hear your voice

1:26:09.920,1:26:13.250
(In Japanese) Are? Nanka,

1:26:32.527,1:26:33.335
(In Japanese) Hmm, Doushiyokkana

1:26:33.335,1:26:36.080
Fabien-san how can we do?

1:26:44.880,1:26:49.840
yeah I'm looking forward

1:26:51.520,1:26:53.552
very strange

1:27:06.800,1:27:08.451
(In Japanese) A, Kita

1:27:21.840,1:27:23.475
okay do you see my screen now?

1:27:24.274,1:27:27.063
Yes I can see

1:27:27.163,1:27:29.219
okay so I will

1:27:29.219,1:27:31.711
go fast to, sorry for some delay

1:27:31.711,1:27:37.511
so I'm Jean-Pierre Merlet 
I'm working as a robotician so I'm not an artist at all

1:27:37.511,1:27:40.271
I'm working in a team which is called HEPHAISTOS

1:27:40.271,1:27:45.503
which is working basically on providing assisted device for frail people

1:27:45.503,1:27:47.465
um

1:27:47.465,1:27:54.480
probably that 
I don't see my screen so I cannot go up and down

1:27:57.760,1:27:59.493
okay

1:27:59.493,1:28:05.252
so what are the benefits for 
scientists to work with athletes

1:28:05.252,1:28:06.867
this is the question I have to raise

1:28:06.867,1:28:09.543
what are 
the benefits for artists to work with scientists

1:28:09.543,1:28:14.960
those opposite and our other application 
domains may benefit from such a collaboration

1:28:16.320,1:28:18.845
it's difficult to work with artists for a 
scientist

1:28:18.845,1:28:22.503
and I assume that it's difficult for artists to work with scientists

1:28:22.503,1:28:24.050
because 
there are a lot of problems

1:28:24.050,1:28:28.343
so what are the benefits for scientists?

1:28:28.343,1:28:33.200
Well, you know in our research institution

1:28:33.200,1:28:38.275
it's not really expected and sometimes 
it's even seen as quite suspect

1:28:38.275,1:28:44.171
Furthermore, from an evaluation from a scientist evaluation 
viewpoint

1:28:44.171,1:28:47.866
it's difficult to evaluate because we don't have indicators

1:28:47.866,1:28:52.800
and collaboration with 
artists requires a huge understanding effort

1:28:55.280,1:28:58.179
what are the benefits for artists to work with 
scientists?

1:28:58.179,1:29:02.445
well a major difficulty is that

1:29:02.445,1:29:08.049
the scientist is some kind of in between 
between the artists and the work

1:29:08.049,1:29:09.840
most of them are

1:29:10.560,1:29:14.851
many of the artists are not aware of technological 
possibilities

1:29:14.851,1:29:22.296
so they have an attitude of self-censorship that limits the creativity

1:29:22.296,1:29:28.769
and 
they're also the understanding effort for our people

1:29:28.769,1:29:32.421
they have also to understand 
scientists

1:29:32.421,1:29:36.037
do you still hear me?

1:29:36.037,1:29:40.160
I'm not sure because I have absolutely 
no sound

1:29:40.160,1:29:42.240
no that's, yeah? it's okay

1:29:42.240,1:29:48.216
So let's go to to a practical example to show 
you that

1:29:48.216,1:29:51.840
in spite of these drawbacks we have

1:29:53.440,1:29:54.640
the possibility

1:29:54.640,1:29:57.600
and it's a very interesting 
possibility to collaborate with artists

1:29:58.400,1:30:02.046
I will illustrate site on this example where we 
have a robot

1:30:02.046,1:30:05.059
which is called the cable driven parallel robot

1:30:05.059,1:30:11.952
and the purpose of this robot is 
to be able to move the point b that you see on the drawing

1:30:11.952,1:30:16.043
the platform with this guy underside

1:30:16.043,1:30:20.338
moves 
his platform in all direction x y z

1:30:20.338,1:30:25.378
so we can raise the platform go to left go backwards and upward

1:30:25.378,1:30:30.069
and to do that, we have four cables

1:30:30.069,1:30:31.840
which 
are attached to the platform

1:30:32.480,1:30:37.206
and are also attached on the winch at point a

1:30:37.206,1:30:40.400
and the winch allowed to change the cable lengths

1:30:41.760,1:30:45.983
and by an appropriate control of the cable length

1:30:45.983,1:30:48.960
we can change the position of the platform at will

1:30:52.160,1:30:52.660
oops

1:30:54.960,1:31:00.116
there is an application of this kind of robot 
in the earth's domain

1:31:00.116,1:31:03.317
which is assistance to mobility for frail people

1:31:03.317,1:31:06.535
for example where we're 
making transfer operation

1:31:06.535,1:31:12.859
helping them to go for example to go to a sitting from a sitting 
position to a standing position

1:31:12.859,1:31:15.184
and also for working assistance

1:31:15.184,1:31:18.880
with the benefits of providing 
autonomy they are able to do something that

1:31:20.320,1:31:23.411
before they were not able to do alone

1:31:23.411,1:31:26.720
which 
improves self-esteem (and) improved social relationship

1:31:27.280,1:31:30.844
and it's also very interesting for doctors

1:31:30.844,1:31:32.741
for monitoring the health of the subject

1:31:32.741,1:31:37.135
because this platform is instrumented to give 
medical information

1:31:37.135,1:31:42.537
so let's just show me (let me show you) a short video

1:31:42.537,1:31:43.695
if it works

1:31:43.695,1:31:47.138
I hope you can see 
the video

1:31:47.138,1:31:49.446
you see a patient on the bed

1:31:49.446,1:31:51.312
the robot is coming down

1:31:51.312,1:31:53.916
the patient is in 
a medical harness

1:31:53.916,1:32:01.527
and I'm losing the job but basically the patient can do it alone

1:32:01.527,1:32:05.199
the robot will lift the patient to move her

1:32:05.199,1:32:06.744
in a wheelchair

1:32:06.744,1:32:11.588
so she will be now again 
fully autonomous

1:32:11.588,1:32:14.960
I will stop the video

1:32:17.760,1:32:22.889
but already this robot has this kind of having inclusion of art

1:32:22.889,1:32:26.604
so for example maybe you know the pink singer

1:32:26.604,1:32:29.490
and this is one of her 
public performance

1:32:29.490,1:32:35.401
she moves over the crowd using this cable powered robot

1:32:35.401,1:32:38.043
and you can see 
she will do something very french

1:32:38.043,1:32:42.055
at the point I don't see the video on the screen

1:32:42.055,1:32:44.259
you don't see the video?

1:32:44.259,1:32:45.440
no video

1:32:48.000,1:32:50.250
not this one not the previous one as 
well

1:32:50.250,1:32:50.750
pdf

1:32:50.750,1:32:53.536
I'm sorry but okay

1:32:53.536,1:32:57.178
this is probably the same issue with my screen

1:32:57.178,1:33:00.000
i 
will skip that for the sake of time

1:33:02.800,1:33:11.478
in 2018 we have a magic encounter with 
an artist whose name is Anne-Valérie Gasc

1:33:11.478,1:33:15.877
during a workshop devoted to the use of robot in 
architecture

1:33:15.877,1:33:18.880
and Anne-Valérie was looking for a machine

1:33:18.880,1:33:26.560
with the purpose of 3d printing a 
structure on large scale (with) dozens of metals

1:33:26.560,1:33:30.480
the printing material is glass microbeads

1:33:30.480,1:33:32.947
the machine has to follow a fixed trajectory

1:33:32.947,1:33:35.878
and deposit layers of glass powder

1:33:35.878,1:33:42.640
but there is no gluing element in the product so that the 
structure slowly collapse after each layer

1:33:44.720,1:33:49.840
and an exhibition of this structure 
was scheduled for the summer of 2019

1:33:50.480,1:33:53.040
in an art center located close to paris

1:33:55.520,1:33:58.206
we get interested in this project

1:33:58.206,1:34:06.675
because we have made a huge effort on the theoretical modeling and control of 
this kind of robot

1:34:06.675,1:34:14.304
we are interested in long-term deployment because this allowed to test the 
robustness of our system

1:34:14.304,1:34:18.688
and especially to detect failure understanding why something 
has failed

1:34:18.688,1:34:21.200
and detecting unexpected behaviors

1:34:23.200,1:34:28.240
the objectives we have was basically increasing 
the safety and performance of the system

1:34:30.160,1:34:34.733
for dealing with uh our assistance problem

1:34:34.733,1:34:40.075
so you see a picture of the exhibition place it was huge

1:34:40.075,1:34:45.840
the length was about 40 
meter so it's about 20 meter 25 meter

1:34:47.680,1:34:51.459
you see there's a drum that is moved by the robot

1:34:54.880,1:35:00.799
I will not show the video it's it's 
basically bad but I cannot do anything to get that

1:35:00.799,1:35:05.360
also maybe I try maybe let me 
try something

1:35:05.360,1:35:09.400
I hope I will not lose

1:35:20.320,1:35:22.658
maybe you switch the video now

1:35:25.954,1:35:28.146
Do you see the video?

1:35:28.146,1:35:31.136
ok, I can see

1:35:31.136,1:35:33.360
I don't hear you

1:35:33.360,1:35:35.944
I can see the video

1:35:35.944,1:35:38.943
okay, all right

1:35:40.430,1:35:47.120
So, (unintelligible noise)

1:35:47.120,1:35:54.242
and now it's deploying the powder on the structure

1:35:57.760,1:36:01.937
okay we'll stop the video move back to the 
talk

1:36:01.937,1:36:06.400
I hope you see the the slide now

1:36:08.080,1:36:10.716
so some result of this exhibition

1:36:10.716,1:36:14.071
the exhibition 
lasts for one month and a half

1:36:14.071,1:36:17.432
the robot traveled for more than four kilometers

1:36:17.432,1:36:23.323
walking in 
average four hours and fifteen minutes per day

1:36:23.323,1:36:28.350
76 layers of glass powder were deposited

1:36:28.350,1:36:31.120
which represents 1.5 tons of glass

1:36:31.920,1:36:33.661
and we have some failures

1:36:33.661,1:36:36.480
one cable 
breakdown during the installation

1:36:37.520,1:36:42.053
and two small failure encoder on one axis 
model

1:36:42.053,1:36:44.480
but so was it was not really important

1:36:46.800,1:36:50.382
next we move to ICRA 2020

1:36:50.382,1:36:59.180
the same exhibition was scheduled to be part of a big 
robotics conference

1:36:59.180,1:37:01.177
which is, whose name is ICRA

1:37:01.177,1:37:07.760
which have 5000 plus participants in Paris during June 2020

1:37:07.760,1:37:14.480
we have improved the system but unfortunately ICRA was postponed because of the Covid

1:37:14.480,1:37:20.080
and our new exhibition will take place during the summer of this year in a museum close to to this

1:37:22.240,1:37:24.801
lesson learned

1:37:24.801,1:37:28.107
from art to science

1:37:28.107,1:37:33.852
we have 
received a huge benefit in taking part of the exhibition

1:37:33.852,1:37:42.380
from a scientific viewpoint we are a 
single team in a world which is able to master a very difficult issue in this kind of robots

1:37:42.380,1:37:47.200
furthermore this experiment they offer

1:37:47.200,1:37:50.880
unique test bed for researchers 
working on dune information

1:37:50.880,1:37:53.213
dunes formation modeling

1:37:53.213,1:37:59.360
but still many of the 
colleagues, our research colleagues, indicates that

1:37:59.360,1:38:00.629
more or less valley

1:38:00.629,1:38:01.594
yeah

1:38:01.594,1:38:04.160
could 
you please (move) back to the pdf?

1:38:06.240,1:38:07.663
back to?

1:38:07.663,1:38:14.415
we see the stopped video so 
could you please back to pdf?

1:38:14.415,1:38:17.439
okay um...

1:38:19.200,1:38:21.650
let me see

1:38:30.640,1:38:31.336
okay

1:38:31.336,1:38:33.069
now you sh...

1:38:33.069,1:38:34.488
okay you skip my slide

1:38:34.488,1:38:38.240
so I'm backing up lesson learned

1:38:38.240,1:38:42.080
from a scientific viewpoint this 
experiment was very interesting

1:38:42.080,1:38:49.920
but still many of our research colleagues state 
more or less overly that this is not real science

1:38:55.040,1:39:02.320
it's also said that the government's 
level of the interdisciplinarity is

1:39:02.320,1:39:03.978
very good is a necessity

1:39:03.978,1:39:08.880
but in the practice 
of such official speech is quite different

1:39:10.301,1:39:14.640
because the evaluation committee are not 
very comfortable with such a collaboration

1:39:17.440,1:39:23.507
what we need also is that discussion with doctors and artists have a lot of similarity

1:39:23.507,1:39:28.614
they have a different language (and) they have a different 
level of scientific knowledge

1:39:28.614,1:39:35.680
but for us it's quite uh interesting because this exhibition 
has facilitated our communication with doctors

1:39:37.200,1:39:40.287
now lesson learned from science to 
art

1:39:40.287,1:39:45.420
many artists believes that that animating an artwork is a complex and 
expensive task

1:39:45.420,1:39:53.200
this is no more true, even for motion except for very large artwork

1:39:53.200,1:40:00.084
To illustrate that in 2015 we have organized 
a workshop

1:40:00.084,1:40:02.631
called computer science for art

1:40:02.631,1:40:04.094
which results

1:40:04.094,1:40:06.061
so it was a five day workshop

1:40:06.061,1:40:09.280
which 
resulted in a concept at the end of the workshop

1:40:09.280,1:40:13.350
with the device developed by the artist during 
the workshop

1:40:13.350,1:40:15.684
and I can show you a picture of this concept

1:40:15.684,1:40:20.352
you see some strange machines that 
were making musics

1:40:20.352,1:40:22.640
both on the ground on the table

1:40:23.360,1:40:25.689
you see a dancer

1:40:25.689,1:40:29.467
for example the dancer as an 
accelerometer on her hand

1:40:29.467,1:40:33.109
so that the music was changing according to a motion

1:40:33.109,1:40:35.996
so I moved to conclusion

1:40:35.996,1:40:37.185
and sorry for the delay

1:40:37.185,1:40:43.590
for a scientist wondering on domains quite different from our 
main research field is very fruitful

1:40:43.590,1:40:48.684
this allows us to develop new algorithms new software newer 
methodologies

1:40:48.684,1:40:55.153
and all this work may be used for other research topics

1:40:55.153,1:41:01.058
in our case working with 
artists has allowed us to improve our medical device

1:41:01.058,1:41:04.156
facilitate our discussion with doctors

1:41:04.156,1:41:09.427
but also to better understand human acceptation of the device

1:41:09.427,1:41:12.318
which is quite essential 
for us

1:41:12.318,1:41:15.600
and to better understand the patients needs

1:41:15.600,1:41:20.201
so this will end my presentation, and sorry for 
the technical problem

1:41:20.201,1:41:22.480
thank you for your attention

1:41:25.360,1:41:30.080
thank you very much for an excellent demonstration

1:41:30.080,1:41:33.771
I understand this conclusion very much

1:41:33.771,1:41:46.494
so 
this time this is the end of a session one, and from now uh we'd like to have some Q&A 
session

1:41:46.494,1:41:53.218
so if any and anyone has a question for the speakers

1:41:53.218,1:42:02.181
could you please raise your 
hand or say something from my microphone?

1:42:03.280,1:42:04.479
hello

1:42:05.877,1:42:08.257
Please, Assayag-sensei

1:42:17.222,1:42:20.120
You have any question? no?

1:42:28.880,1:42:33.600
maybe you started a question 
uh quick you know maybe

1:42:33.600,1:42:36.705
yes I have so many questions

1:42:36.705,1:42:41.982
Assayag-sensei, I'm very interested by your presentation

1:42:41.982,1:42:50.458
I think IRCAM is very good to improve and advance the possibility of music

1:42:50.458,1:42:53.601
so I'm very impressed by your work

1:42:53.601,1:42:55.000
how can I say

1:42:55.000,1:42:59.179
the guitar with a vibration

1:42:59.179,1:43:08.339
so how what is the 
initial motivation of, to create this kind of guitar?

1:43:08.880,1:43:12.195
okay so uh as I said

1:43:12.195,1:43:17.613
one of the 
fundamentals of the REACH project

1:43:17.613,1:43:24.686
is to state that creativity shared with the machine

1:43:24.686,1:43:29.182
can only be an emergent process

1:43:29.182,1:43:34.979
that will appear in the course of interaction

1:43:34.979,1:43:45.491
and so that you cannot really describe what is creativity for a machine

1:43:45.491,1:43:48.851
and maybe this doesn't have even meaning

1:43:48.851,1:43:54.701
but you can describe creative or 
co-creative processes that are emerging

1:43:54.701,1:43:57.632
because you have a complex interaction 
between agents

1:43:57.632,1:44:03.874
artificial or humans who are related by a cross-learning 
phenomenon

1:44:03.874,1:44:07.907
so once we have moved into this realm

1:44:07.907,1:44:13.200
we have realized that in 
order to really have this convergence between

1:44:13.200,1:44:19.280
cyber augmentation which is augmenting the 
the the capacities of various algorithms

1:44:19.280,1:44:25.360
and human augmentation which is augmenting 
the capacities of human towards the algorithm

1:44:25.360,1:44:28.322
we needed, we really needed a physical step

1:44:28.322,1:44:34.196
that is a step where there would be some embodiment of the human

1:44:34.196,1:44:37.232
into the process of interacting with 
the machine

1:44:37.232,1:44:41.571
so the guitar is only the first try that we make

1:44:41.571,1:44:50.561
the first step of of trying to 
to to create the condition for such a physical embodiment of the human

1:44:50.561,1:45:00.849
by embedding the algorithm 
into a physical device that the human really has against his body and feels like an extension 
of the of his body

1:45:00.849,1:45:03.255
but it is just the first experiment of course

1:45:03.255,1:45:07.501
we would like to design many 
other instruments or any kind of devices

1:45:07.501,1:45:12.749
where this emergence of co-creativity between human and 
machines

1:45:12.749,1:45:16.379
will be really the result not only of an intellectual process

1:45:16.379,1:45:18.745
but of a physical embodiment 
of the human

1:45:18.745,1:45:22.875
and maybe sometimes because we we had a robotics presentation just before

1:45:22.875,1:45:28.681
and maybe also a physical embodiment of artificial creators too

1:45:28.681,1:45:36.080
thank you very much I'm very 
impressed by your idea of co-creativity with machine

1:45:36.080,1:45:40.389
and then I have one question to Mr. Tokui

1:45:40.389,1:45:44.271
and I already 
asked the question

1:45:44.271,1:45:46.160
so could you please answer it?

1:45:47.680,1:45:52.960
so how I train my GAN model 
on rhythm, that was question correct?

1:45:52.960,1:46:03.351
okay so maybe I was not so clear about my project

1:46:03.351,1:46:09.232
so the first step was uh to train a normal GAN model

1:46:09.232,1:46:13.802
a Generative Adversarial Network model on 
rhythm data

1:46:13.802,1:46:25.561
so it's I think relatively easy for you know GAN's network to capture the the essence of rhythm pattern

1:46:25.561,1:46:29.920
But I thought it's just

1:46:29.920,1:46:34.809
another imitation of human creativity in a way

1:46:34.809,1:46:46.124
that's why as a second step I added another discriminator to the original GAN framework

1:46:46.124,1:46:55.534
then the second discriminator is not is not expected to classify

1:46:55.534,1:47:05.606
training data from artificial data

1:47:05.606,1:47:13.520
but it's expected 
to classify the genre of music generated

1:47:15.944,1:47:27.319
so the original discriminator 
was trained to classify

1:47:27.319,1:47:31.579
the real data from the fake one right?

1:47:31.579,1:47:37.584
that's the core concept of the Generative Adversarial Network

1:47:37.584,1:47:46.240
then I added a second discriminator which 
does the classification of musical genres

1:47:48.880,1:48:00.374
so the origin generator 
was uh uh trained to confuse not only the original discriminator

1:48:00.374,1:48:06.312
but also the second genre 
classification discriminator

1:48:06.312,1:48:07.520
so I expect

1:48:09.280,1:48:19.876
at the end generator will be able to generate 
something that sounds like a realism pattern

1:48:19.876,1:48:27.945
but these are patterns that 
don't belong to any genres

1:48:27.945,1:48:36.082
So you created a triangle of discriminators combining them

1:48:36.082,1:48:40.519
I understand a little bit

1:48:40.519,1:48:43.200
Okay, Thank you very much

1:48:43.200,1:48:48.827
the original idea was, when you think about artists

1:48:48.827,1:48:56.018
maybe think about any famous artist, picasso for example

1:48:56.018,1:49:12.841
so he started to, you know, train himself to capture the...

1:49:12.841,1:49:17.069
Sorry, let me rephrase again

1:49:17.069,1:49:28.284
so picasso, or any other artist should start painting to imitate somebody 
else's style right?

1:49:28.284,1:49:32.362
so I want to be like this artist or that artist

1:49:32.362,1:49:48.559
But Picasso or any other artist at some point they start trying to deviate from the existing styles

1:49:48.559,1:49:57.777
so there is some kind of, like how I can say,

1:49:57.777,1:50:03.880
the conflict between 
like staying in the existing style

1:50:03.880,1:50:08.411
and also, like deviating from the existing style

1:50:08.411,1:50:14.188
so there is very delicate balance between these two directions

1:50:14.188,1:50:24.400
so I wanted to make 
realize that conflict within the GAN framework

1:50:24.400,1:50:26.350
yeah I understand okay.

1:50:26.350,1:50:32.979
you mean that all artists have uh their own discriminator in (of) their own

1:50:33.079,1:50:36.712
The one is to imitate another 
artist

1:50:36.712,1:50:43.640
and another discriminator is to escape from the uh traditional art

1:50:43.640,1:50:48.754
so i understand that it's very interesting and it works

1:50:48.754,1:50:49.716
very well

1:50:49.716,1:50:53.240
Thank you very much for your presentation

1:50:54.442,1:51:01.404
Merlet-san, can you hear me? I have a question for your presentation

1:51:01.404,1:51:11.519
And I understand that you are a scientist and 
uh have collaborated with us artists

1:51:11.519,1:51:17.600
So is there any point, the important point

1:51:17.600,1:51:24.418
to successful collaboration 
with artists?

1:51:24.418,1:51:26.259
what is the point

1:51:28.600,1:51:30.498
Ah, yeah

1:51:31.680,1:51:40.880
this is, we have to adopt a very different mind when working with artists

1:51:40.880,1:51:46.168
compared to other work we may do with companies 
and stuff like that

1:51:46.168,1:51:48.545
for two reasons

1:51:48.545,1:51:52.737
because they have the, main for many reasons in fact

1:51:52.737,1:51:58.150
they have a different language, and we have a different language

1:51:58.150,1:52:05.503
so we have to understand 
each other sometimes we use the same word but with different meaning

1:52:05.503,1:52:11.040
so that we need to create 
some kind of dictionary between the two community

1:52:12.401,1:52:20.882
then the artists are not always aware of all 
of our technological and scientific constraints

1:52:20.882,1:52:29.280
well what is really make me 
afraid (what makes me afraid) some time is that

1:52:29.280,1:52:36.498
when an artist tell me oh I have just a minor 
detail to change the system

1:52:36.498,1:52:44.338
the last time they the artists tell us because we work with many 
different artists but the one we are working with right now

1:52:44.338,1:52:51.280
the last time she tell me that 
results in 400 hours of work changing everything

1:52:51.280,1:52:52.705
But it's okay

1:52:52.705,1:53:02.182
at the same time we really 
learn from the way people are seeing our work

1:53:02.182,1:53:07.826
the view of the artist is very different from 
the view we have

1:53:07.826,1:53:10.449
and it's very close to what the patient tells

1:53:10.449,1:53:12.457
so it's very important to have this 
discussion with us

1:53:12.457,1:53:14.240
because it's opened our mind

1:53:16.941,1:53:21.924
Okay, thank you very much wonderful episode

1:53:21.924,1:53:28.200
And thank you for all and then we'd like to have some uh...

1:53:32.223,1:53:37.730
Tokui-sensei, can you read the chat screen?

1:53:37.730,1:53:43.939
Magali-san has a question to Tokui-sensei

1:53:46.240,1:53:49.491
sharing the same point of view uh which are the 
ownership

1:53:49.491,1:53:53.280
Ah, I see and this is not question I think

1:53:53.280,1:53:59.591
then I'd like to have a coffee break for now

1:53:59.591,1:54:05.037
and we can see the screen of a video from *arya material(?)*

1:54:05.037,1:54:13.639
and you can see the 
video from (that) I took in this state in Europe

1:54:13.639,1:54:21.840
Look through the video with a cup of coffee and sandwich

1:54:32.240,1:58:55.800
A video interview of a french person

1:58:58.480,1:59:06.800
five years ago I saw some small demonstrations 
of it doing like really expressive remapping

1:59:06.800,1:59:13.842
from like gesture drawing to something somewhat 
photographic I thought that that was

1:59:13.842,1:59:20.248
an amazing way to encapsulate knowledge of the figure is 
in a neural network

1:59:20.248,1:59:26.204
I can see a lot of the same challenges that the neural network will try to 
understand

1:59:26.204,1:59:29.345
that an artist tries to understand

1:59:29.345,1:59:38.400
the artist controls it from his imagination and 
his ideas and then he kind of confers the routine

1:59:41.760,1:59:44.960
that's what I discovered that I was able to do

1:59:44.960,1:59:51.280
with the AI at a University I did arts 
but engineering was my primary degree

1:59:51.280,2:00:00.320
my work is somewhat of the understanding from 
engineering and then my artistic study as well

2:00:03.680,2:00:07.120
and so a lot of my photography 
initially was to support

2:00:07.120,2:00:11.360
my my own understanding but 
also the anatomy lectures

2:00:16.880,2:00:23.959
and that's usually how the the project starts 
with kind of a concept that I visualize in my imagination

2:00:23.959,2:00:29.840
and then I try to see if 
it fits within the techniques that I've

2:00:29.840,2:00:32.323
explored whether it was possible

2:00:32.323,2:00:35.920
I guess one 
of the reasons why maybe my stuff is different

2:00:36.800,2:00:43.680
I try really ridiculous ideas just to see how 
interestingly they fail that part of the process

2:00:43.680,2:00:51.533
is maybe a scientist or a researcher but even as 
an artist the failure is sometimes beautiful

2:00:51.533,2:01:00.640
I understand the boundaries of what machine learning 
can do and then just test it and see what happens

2:01:00.640,2:03:13.520
Another video is playing back

2:03:13.520,2:03:16.880
from Japan uh his name is Akira

2:03:16.880,2:03:24.000
just approached the idea of creating characters 
because he worked for me was like really

2:03:24.000,2:03:29.541
mind-blowing I decided to uh to find my way 
as well

2:03:29.541,2:03:34.735
I'm trying to convince myself to finish

2:03:34.735,2:03:46.334
so what I want to do is like a massive 
project I would say like 10 000 different creatures

2:03:46.334,2:03:55.840
the tools allow 
me to work on at this scale and I want to try to see what comes out of it

2:03:55.840,2:08:49.345
Another video is playing back

2:09:06.720,2:09:10.620
okay uh thank you very much

2:09:12.560,2:09:17.241
so I'd like to restart the session

2:09:17.241,2:09:20.720
from now we'd like to start session two

2:09:22.800,2:09:31.840
after the first presentator is professor 
Lionel Obadia from University of Lyon 2.

2:09:32.800,2:09:38.320
Obadia-sensei, thank you very 
much for attending this symposium

2:09:38.320,2:09:40.346
could you please start your presentation

2:09:40.346,2:09:42.467
I'm trying you hear me

2:09:42.467,2:09:44.634
yes I can hear you

2:09:44.634,2:09:49.691
all right fine I don't have videos and I hope 
everything will feel right for my presentation

2:09:49.691,2:09:55.058
and I'm really happy and to be there thanks 
for the invitation

2:09:55.058,2:09:59.709
I see that there are a couple of people that I know around the table

2:09:59.709,2:10:01.180
but it is 
another story

2:10:01.180,2:10:04.819
so I share my presentation right now

2:10:06.160,2:10:07.759
and

2:10:09.440,2:10:10.098
I can see

2:10:10.098,2:10:10.936
can you see it?

2:10:10.936,2:10:11.789
yes

2:10:11.789,2:10:15.967
all right let's 
go for it

2:10:15.967,2:10:19.040
I'm just trying to have this um

2:10:19.040,2:10:24.813
uh well well well, I'm sharing but I want to have 
this

2:10:24.813,2:10:26.244
okay I'm going like that

2:10:26.244,2:10:28.943
okay do you see just one one slide?

2:10:28.943,2:10:30.000
okay perfect

2:10:30.000,2:10:31.043
okay great

2:10:31.043,2:10:37.240
this is a very long title and a very short reflection that you will see

2:10:37.240,2:10:41.358
and I'm a social 
and cultural anthropology specialized in religion

2:10:41.358,2:10:44.533
Asian religion to be a clear

2:10:44.533,2:10:48.132
and I've recently, since a couple of years (ago),

2:10:48.132,2:10:54.439
I'm converting myself to the steganological study of 
digital technologies

2:10:54.439,2:10:58.000
and robotics and and so on

2:10:58.000,2:11:05.831
so just one point if I have a problem for the presentation

2:11:05.831,2:11:09.878
since I do not see, all right, I do not see my screen

2:11:09.878,2:11:20.878
yeah, and, so a couple of 
reflections starting from fieldwork that I've been conducting season since one two years ago

2:11:20.878,2:11:27.323
I tried 
to submit an ERC (European Research Council) advanced (grant) but uh unfortunately, they,

2:11:27.323,2:11:29.269
contrary to other colleagues around the table

2:11:29.269,2:11:33.032
it was not successful this time that it will be resubmitted this year

2:11:33.032,2:11:40.376
but digital magic and I'm 
quite glad to hear that professor Merlet talk about magic in the context of robotics

2:11:40.376,2:11:43.280
this is exactly what I'm trying to explore now

2:11:43.280,2:11:52.398
And so I will talk about today, humans and the the tendency and the and the trends in robotics

2:11:52.398,2:11:55.209
and in world society to consider 
that

2:11:55.209,2:12:02.037
robots and all these kind of 3d AI forms have to be human shaped

2:12:02.037,2:12:08.356
and what kind of cultural 
imagination it brings at the forefront of the agenda of a

2:12:08.356,2:12:13.120
reflection of technology and culture, 
technology and society, and technology and history

2:12:13.120,2:12:16.872
so we all know that the digital revolution impacts

2:12:16.872,2:12:22.226
coming in there in a wide range of form and effect (in) now

2:12:22.226,2:12:26.083
we all agree that we live in 
a networked connected world and society

2:12:26.083,2:12:29.088
and interaction with these devices, small ones (and) big ones

2:12:29.088,2:12:36.576
have become natural and natural means in our lexicon (to be) culturally accepted

2:12:36.576,2:12:43.957
So we are, many now studying these new attitudes representation and cultural frameworks and imagination

2:12:43.957,2:12:48.330
that give means to technology as they infused society and daily lives

2:12:48.330,2:12:55.743
and there is this kind 
of interaction in between technologies and culture and society complete

2:12:55.743,2:13:00.000
and ongoing uh feedback in between the two

2:13:00.080,2:13:02.991
my anthropological point of view

2:13:02.991,2:13:05.414
it's culturally focused, (and) it's comparative

2:13:05.414,2:13:11.559
and I'm conducting ethnography of labs, exhibitions, enterprises, university everywhere

2:13:11.559,2:13:20.349
where I can find people that are trying to design, develop, test, use, and socially distribute these very strange devices

2:13:20.349,2:13:21.877
called AI robots.

2:13:21.877,2:13:25.609
so I'm in the second month (as a) professor of anthropology at the University of Lyon

2:13:25.609,2:13:28.299
but I'm in the second month right now, in two labs.

2:13:28.299,2:13:33.672
The first one is (in french) Centre d'Internet de Sociétés, Center for the Study of Internet and Society

2:13:33.672,2:13:39.269
so this is all about communication device and the sharing information and so on

2:13:39.269,2:13:45.551
and I'm also associated member of the Institut des Systèmes Intelligents et de la Robotique

2:13:45.551,2:13:48.013
Institute for Intelligent System and Robotics

2:13:48.013,2:13:53.088
where I'm conducting my field work among other places

2:13:53.088,2:13:54.630
where I'm doing this field works

2:13:54.630,2:14:05.327
and my paper will emphasize images and belief through attitudes, cultural expression, (and cultural expression) at large including artistic one

2:14:05.327,2:14:09.653
but I will 
not talk about arts in this presentation today

2:14:09.653,2:14:14.789
this focus on robots especially robots, rather than AI and other digital device

2:14:14.789,2:14:18.526
this focus is mainly due to the fact that robots

2:14:18.526,2:14:27.998
indeed raise the crucial issue of human shape form of technological creations

2:14:27.998,2:14:34.990
so this paper is not on art except that I'm participating on an ongoing research

2:14:34.990,2:14:37.863
with people that were are working on art

2:14:37.863,2:14:44.143
this is a seminar titled robots on stage interdisciplinary conversions between robotic and theater

2:14:44.143,2:14:46.288
this is a network and people are working together

2:14:46.288,2:14:48.496
you can see an image of what they do

2:14:48.496,2:14:52.961
they are studying plays and robots in place and AI in plays

2:14:52.961,2:14:59.492
and this is one of the *place* that I've been studying and presented in this network

2:14:59.492,2:15:03.660
but my focus will be on arts let's say popular arts

2:15:03.660,2:15:05.885
the movies, literature and online

2:15:05.885,2:15:10.951
So these robots, AI and other so-called creators

2:15:10.951,2:15:14.172
as seen from the side of social sciences and humanities

2:15:14.172,2:15:20.093
means not users but designers to users on the human side

2:15:20.093,2:15:26.008
and the empirical studies demonstrate that we have the evidence that AI is everywhere

2:15:26.008,2:15:33.079
but still it is nowhere because sometimes with the lack of materiality and the previous papers

2:15:33.079,2:15:38.080
underscore this point that we have to materialize and that,

2:15:38.960,2:15:45.093
Eto-san, your own paper to put emphasis on the materialization and visualization

2:15:45.093,2:15:47.649
of these devices and software

2:15:47.649,2:15:51.280
so it depends on the perception of their silence and materiality

2:15:51.920,2:15:57.255
and the same for the degree of reality of the integration of this device in our life

2:15:57.255,2:16:01.289
unless I left beside the issue of cultural difference

2:16:01.289,2:16:05.501
in between France and Japan, and France and the United states and so on

2:16:05.501,2:16:12.109
and countries with a lower economic development for instance

2:16:12.109,2:16:19.200
where the issue of this technology is an issue of cultural framework by which this technology are understood

2:16:19.760,2:16:22.233
is raised in a quite different way

2:16:22.233,2:16:30.091
but we'll talk about culture and society in general because of the very fast generalization

2:16:30.091,2:16:34.075
then this is important to take into account that

2:16:34.075,2:16:38.504
there are the inequal social and cultural distribution of device

2:16:38.504,2:16:41.382
and their availabilities, skills, and knowledge

2:16:41.382,2:16:44.465
and I heard several times this morning

2:16:44.465,2:16:52.866
the issue 
of failures the issue of not understanding the issue of something wrong in the behavior of the machines

2:16:52.866,2:16:55.593
and still this is really important to understand

2:16:55.593,2:16:58.317
or as well what humans provide as meanings

2:16:58.317,2:17:01.320
and especially when it's about non-rational meanings.

2:17:01.320,2:17:10.290
again these robots AI software and algorithm and so on are distributed on a different scale

2:17:10.290,2:17:13.474
they are very small one that is hidden for instance

2:17:13.474,2:17:16.477
in a smartphone application

2:17:16.477,2:17:22.763
and other ones that take the shape of a big robot that you can face you can have a face-to-face interaction

2:17:22.763,2:17:28.560
then one thing is striking is the fact that

2:17:28.560,2:17:34.971
not most not all but a significant 
part of these devices are shaped against

2:17:34.971,2:17:39.977
the human face or human shape or 
human body shape

2:17:39.977,2:17:42.278
and it raised the question of

2:17:42.278,2:17:46.483
are we trying to make new humans or are they still (making) machines

2:17:46.483,2:17:54.552
and it raised the outcomes of the issue of mimesis in between 
humans and machine on both sides for instance

2:17:56.800,2:18:03.398
besides the issue that social sciences and humanities are trying to raise and trying to explore

2:18:03.398,2:18:07.798
is the interaction in between these humans and devices

2:18:07.798,2:18:15.043
and the correspondence in between human to human social relationship and human device relationships

2:18:15.043,2:18:18.058
and in reality only in imagination

2:18:18.058,2:18:21.919
and this is a war scenario for science fiction movies

2:18:22.720,2:18:27.520
machines to machine communication against human 
that you know that this is really dystopic

2:18:28.080,2:18:36.417
and a quite widespread scenario of robots against humans this is one of the most used

2:18:36.417,2:18:42.337
let's say a background by which we imagine uh the the future in movies

2:18:42.337,2:18:49.773
especially in famous north Americans (famous in north America)

2:18:49.773,2:18:55.373
so we have different side, different forms of materiality from flat devices

2:18:55.373,2:18:58.319
screen that are everywhere on 3d devices

2:18:58.319,2:18:59.574
robots for instance

2:18:59.574,2:19:02.844
and 3d that can be real

2:19:02.844,2:19:08.796
if you see a machine acting that's why it's on (what) the professor Merlet has demonstrated

2:19:08.796,2:19:12.998
but also, you can see also 3d device

2:19:12.998,2:19:14.413
this is a 3d representation

2:19:14.413,2:19:20.439
but what's new as an anthropologist I'm interested in the fact that they are continuities and rupture

2:19:20.439,2:19:25.922
in the relationships in between humans and material environment through techniques

2:19:25.922,2:19:29.503
and I'm quite fond of this theory that

2:19:29.503,2:19:33.897
imagine that there is kind of a ongoing relationship

2:19:33.897,2:19:36.960
to materiality and to things that we shape

2:19:38.080,2:19:43.979
so humans seems to have always been 
interested in mediating their relationship to reality

2:19:43.979,2:19:46.058
thanks to technology at large

2:19:46.058,2:19:49.037
start with very very primitive technologies

2:19:49.037,2:19:53.715
and it end up in hyper modern and quick massive wave of all these devices

2:19:53.715,2:19:55.759
that are colonizing our life

2:19:55.760,2:20:00.719
robots conversational agent algorithm software 
robots connected objects and so on

2:20:00.719,2:20:02.902
for many different purposes

2:20:02.902,2:20:06.567
domestic, military, education, artistic purpose for instance

2:20:06.567,2:20:12.969
or some AI generated arts or AI as an inspiration for artists as a 
representation

2:20:12.969,2:20:20.772
then we live in this new ecosystem of so-called "anthropology significant other" are mediated at

2:20:20.772,2:20:24.479
so the anthropological outlook on this

2:20:24.479,2:20:28.625
is that if we raise issues regarding our relationship

2:20:28.625,2:20:32.846
to AI technological device and robots for instance

2:20:32.846,2:20:36.468
there are already topics like ethics and trust,

2:20:36.468,2:20:42.632
something that has been already treated and discussed by psychology, philosophy, and law

2:20:42.632,2:20:45.967
but SSH (Social Sciences and Humanities) can bring like a lot of dimension taste and proof

2:20:45.967,2:20:49.968
from the appeal to robots and AI

2:20:49.968,2:20:54.216
and belief in these devices are animating by something

2:20:54.216,2:20:58.709
and then anthropology, sorry for uh insisting on this point,

2:20:58.709,2:21:04.022
but want to highlight how humans are in practice creative with machine

2:21:04.022,2:21:09.850
and how also they inject imagination futuristic scenario and even present scenario

2:21:09.850,2:21:13.004
and how the scenario infused society

2:21:13.004,2:21:19.906
and my interest raised in the fact that this scenario also impacts different 
sectors society

2:21:19.906,2:21:24.969
including technological ones means that the people that are building these technologies

2:21:24.969,2:21:31.918
are actors like *OOO* and actors and they are influenced

2:21:31.918,2:21:36.640
from the best or for the worst influenced by this imaginary frames

2:21:36.640,2:21:42.720
and then I will focus on image and imagination through these screens and visual culture

2:21:42.720,2:21:49.920
but let's start for the beginning and these new mechanics, automatic robots

2:21:49.920,2:21:54.346
are located according to the frame of imagination at the frontiers between

2:21:54.346,2:21:57.665
humanity and the rationality between fiction and realism

2:21:57.665,2:22:05.545
and especially human with robots that capture maybe most, maybe more than even all the other ones

2:22:05.545,2:22:07.924
this kind of imagination

2:22:07.924,2:22:12.718
and then there is an interesting discussion in robotics right now

2:22:12.718,2:22:16.092
the tracing back to mythological routes

2:22:16.092,2:22:19.359
this is a widespread tendency and there are two trends that

2:22:19.359,2:22:29.617
if you as an anthropologist read literature in robotics, not very technical, but more open to history and culture

2:22:29.617,2:22:34.377
and you see that there are sub-community of roboticians that think that

2:22:34.377,2:22:39.831
AI and robots are in rupture with ancient forms

2:22:39.831,2:22:43.172
means that it used to be some kind of representation

2:22:49.398,2:22:55.654
TALOS that you see that has been built by *ephrais* and the *feistos* have already been mentioned today

2:22:55.654,2:22:59.599
not the program but the the ancient Greek code

2:22:59.600,2:23:10.314
and other ones that think that AI and robots are only the continuity of an ongoing mythological (and) mental scheme in the human brain

2:23:10.314,2:23:18.690
and these continuity can be seen as well in what is called now the animistic design of new technologies

2:23:18.690,2:23:22.259
and the idea that there is something inside

2:23:22.259,2:23:26.959
something that is haunting the technology something like a soul or something (adeptus mechanicus?)

2:23:26.959,2:23:34.884
that does it above or beyond um the rationality and the purely mechanic 
life of things

2:23:34.884,2:23:41.642
and this even turns to a modern religious robot I take two examples here

2:23:41.642,2:23:43.908
and one in China and one in the west

2:23:43.908,2:23:51.911
these are robot priest and in some context, even the religious system clearly accept the presence of robots

2:23:51.911,2:23:55.779
but as vehicles of belief

2:23:55.779,2:24:02.072
and one thing is really important is that we are witnessing something really really different now

2:24:02.072,2:24:09.448
it's a belief in robots and they believe in AI as religious schemes or as a religious object

2:24:09.448,2:24:13.679
and to mention the rise of the thanks to,

2:24:13.680,2:24:18.235
because of Levandowski who used to be a an engineer at Google

2:24:18.235,2:24:23.621
the first church of AI that considered that AI is a godlike create

2:24:23.621,2:24:30.800
but these robots, and I focus here only on robots,

2:24:30.800,2:24:34.376
it comes under a vast array of types and prototypes

2:24:34.376,2:24:39.745
you can have small parts of the body and you can have the full human humanoid body

2:24:39.745,2:24:48.260
and this is thanks to, also a clear and quick advance in personal robotics and biomimetics,

2:24:48.260,2:24:53.429
sensor elaboration, algorithm-inspired emotions, and and so on

2:24:53.429,2:24:58.939
that makes some of the uh organizations and enterprises creating robots

2:24:58.939,2:25:03.578
attempting to create robots more and more resembling to human bodies

2:25:03.578,2:25:08.484
and if you allow me a slogan, because anthropologists like to produce slogan,

2:25:08.484,2:25:14.804
Are we shifting from bios, the system setup, to bios life within these robots

2:25:14.804,2:25:22.406
and this is a kind of witnessing or revealing unveiling this obsession for anthropomorphism

2:25:22.406,2:25:29.831
and one thing is surprising, striking, is even the representation of AI as a software (on) the flat device

2:25:29.831,2:25:35.718
is anthropomorphized as you can see on the on the on the small picture on the right

2:25:35.718,2:25:40.037
because of intelligence and intelligence it's supposed to be in the brain

2:25:40.037,2:25:44.086
but there are also other theories about intelligence

2:25:44.086,2:25:46.318
anyway,

2:25:46.318,2:25:54.799
all this brings us to the idea that we start from and end up in the representation of human body.

2:25:54.799,2:26:00.758
and then these new programs in human centered AI and robotics tend to respond or seem to respond

2:26:00.758,2:26:07.457
to this human tendency to consider technology as a replication of living real hard actions.

2:26:07.457,2:26:14.516
But these humans are flat or 3d, almost human or meta human and so on,

2:26:14.516,2:26:20.736
range among very different forms

2:26:20.736,2:26:25.546
and only the adjective seems to validate

2:26:25.546,2:26:33.781
and you keep the human substantive noon and you take a lot of, they inspire a lot of adjectives (like humans, almost humans, and meta-humans),

2:26:33.781,2:26:42.459
depending on what you mean and there are at least three epistemological regimes that you can raise after this adjective

2:26:42.459,2:26:46.572
for instance, they said like humans almost humans are meta-humans,

2:26:46.572,2:26:53.348
if you consider that these humans resemble humans only if they are almost human

2:26:53.348,2:26:58.733
that they tend to be human that they will be one day, as human or just like human,

2:26:58.733,2:27:04.719
and the meta humans is they are supposed to be evolved humans

2:27:04.719,2:27:10.359
and in my research, I'm conducting a interesting experience (experiment),

2:27:10.359,2:27:17.197
in which I ask people to react in faith in front of all these meta humans for instance

2:27:17.197,2:27:22.238
you see that on my screen this is on the left but on your screen it may be on the right

2:27:22.238,2:27:29.333
this is this they are quite handsome lady this but this person does not exist because it's an AI generated face

2:27:29.333,2:27:34.640
and also there are these double humans for instance

2:27:34.640,2:27:37.784
this character of Star Wars that was in Star Wars one

2:27:37.784,2:27:41.831
and died in the meantime and was recreated through AI techniques

2:27:41.831,2:27:47.477
to incarnate a new character in recent star wars movie

2:27:47.477,2:27:52.928
even if he's dead but he has the same face he has the same movement and of course he has the same voice

2:27:52.928,2:28:04.997
and the digital human experience it's also interesting because it's a conversational agent with face attitudes

2:28:04.997,2:28:10.978
so you feel like you are talking with something that is almost human but not really human

2:28:10.978,2:28:16.398
it's in between and creating a very very strange (thing)

2:28:16.398,2:28:20.873
different ways to being human race

2:28:20.873,2:28:22.925
of course a series of questions

2:28:22.925,2:28:29.242
and I'm trying to frame them after different questions and different theoretical patterns

2:28:29.242,2:28:34.180
to put concept on them

2:28:34.180,2:28:38.126
first the issue that has been raised previously or as well

2:28:38.126,2:28:40.555
the acceptance of these virtual humans

2:28:40.555,2:28:47.520
We, I'm talking in front of people from Japan

2:28:47.520,2:28:55.680
so Mori's famous uncanny valley is still a concept that will still discuss but was just

2:28:55.680,2:29:02.639
a very specific step in the perception and interaction with a very specific type of of

2:29:02.639,2:29:08.249
machine and robot but the uncanny valley has been widespread in the meantime

2:29:08.249,2:29:14.971
and now this is a huge concept that we can manipulate and redefine in order to understand

2:29:14.971,2:29:21.394
what's the thrill that you have when you meet these non-humans but they are also human they are in between

2:29:21.394,2:29:31.498
and this is the open door to understanding the very magical thinking that is in between humans and machine

2:29:31.498,2:29:38.446
so these devices assume different forms they are co-operative, functional, therapeutic, friendly, assistive, and so on

2:29:38.446,2:29:41.258
and they create a vast array of emotion as well

2:29:41.258,2:29:48.083
but these emotions are mixed together they create anxiety fear for instance people are really afraid of robots

2:29:48.083,2:29:51.829
thanks to science fiction movies or literature

2:29:51.829,2:29:56.996
but also because they are across the road of robots and,

2:29:56.996,2:30:03.423
but this is not always the case most of the of the time the people have fun with robots

2:30:03.423,2:30:06.518
and there and to a certain extent and a very specific context

2:30:06.518,2:30:10.173
they also feel empathy and love and sense of security

2:30:10.173,2:30:14.000
but I'm talking about this therapeutic robot's name Paulo

2:30:14.000,2:30:20.476
which is made for old people with a psychiatric psychological trouble

2:30:20.476,2:30:27.586
and then there are something that is coming in between what I call the three t

2:30:27.586,2:30:32.773
but this isn't that time and if it doesn't work please tell me

2:30:32.773,2:30:43.203
and please create a space for discussion in order to contradict these atoms to theorize the human to robots relationships

2:30:43.203,2:30:48.392
the tools of this robot are first tools but they are also toys we are playing with these devices

2:30:48.392,2:30:51.729
and coming back to this in a second

2:30:51.729,2:30:57.273
and they are also conditions, I mean temptation because we create something more than a relationship

2:30:57.273,2:31:01.920
we get also emotions and we are committed to this device for instance

2:31:01.920,2:31:11.280
this kind of obsession with this device up to sexual desires because now we are witnessing the rise of sexual robots

2:31:11.280,2:31:15.616
and not only in Asian countries but also in Europe and north America

2:31:15.616,2:31:23.760
And then I think that and this may be also a certain way to get closer to the artistic medium

2:31:23.760,2:31:29.600
thinking about play in three different terms of three different definitions of the terms

2:31:29.600,2:31:32.446
first is playing with reality we are in a game

2:31:32.446,2:31:39.174
and there is something happening that we know this is not exactly reality but we are trying to play with reality

2:31:39.174,2:31:42.917
and the second is to play in a non-real but real context

2:31:42.917,2:31:46.857
I mean playing like you are a character in a theater

2:31:46.857,2:31:51.869
then you knew, you know that you are doing something that seems real but it's not real

2:31:51.869,2:31:55.705
that's like a game but now you are playing like a character

2:31:55.705,2:32:02.411
and all this brings us to play as fun because people enjoy doing this thing

2:32:02.411,2:32:10.851
they enjoy, they are they have a lot of positive emotion, and they are also counterbalanced by negative emotions at that time

2:32:10.851,2:32:19.508
but these emotions this effervescence against robots and the relationship with robots

2:32:19.508,2:32:23.464
give rise to really interesting scenarios from the science fiction

2:32:23.464,2:32:30.079
and there are four examples of robots that are purely autonomous imaginative

2:32:30.079,2:32:34.949
they are driven by emotions even if they are not supposed to have emotion for instance

2:32:34.949,2:32:42.478
in the lady on the right is a robot named Arisa in a series that you can find on Netflix Better Than Us

2:32:42.478,2:32:49.027
And she ends up in sacrificing herself to prevent the life of the family

2:32:49.027,2:32:52.012
and she is in love with the dad of the family

2:32:52.012,2:32:56.719
but there as you can see also *Yule Bruner* just before is

2:32:56.719,2:33:06.174
is a pure emotionless robot he's killing people in the first movie in the 70s of Westworld

2:33:06.174,2:33:11.731
but he's driven by anger so he shows no emotion

2:33:11.731,2:33:16.775
but he's killing people because he wants to he wants revenge against the human

2:33:16.775,2:33:22.841
all this is developed in the realm of scenario in the realm imagination and so on

2:33:22.841,2:33:31.878
but on the field when I'm studying for instance in the easier this robot that you can see on the on the left

2:33:31.878,2:33:40.148
the so-called Baxter robot in which their motion trying to trying to make this motion more sophisticated

2:33:40.148,2:33:43.804
and the two examples taken from an exhibition

2:33:43.804,2:33:50.712
in which they are collaborative robots small ones that are supposed to be vacuum cleaner robots collaborative with each other

2:33:50.712,2:33:58.679
and the famous paper which is welcoming people at the start the at the door of the exhibition

2:33:58.679,2:34:02.559
and then we get back to a crude reality and

2:34:02.559,2:34:06.750
one of the researchers in robotics told me, we are quite far from terminator

2:34:06.750,2:34:13.300
and around three, and then why there are so different narrative

2:34:13.300,2:34:20.099
and you know that we (all) know we all know that technologies are embedded in nets of meaning and to enter it in this narrative

2:34:20.099,2:34:26.168
but do these autonomous devices need narrative and of what kind

2:34:26.168,2:34:32.839
and I allow myself the the chance to divide this narrative in between scientific narrative and fiction narrative

2:34:32.839,2:34:39.207
even if they mix each other, the distinction between the the two of them is just purely theoretical

2:34:39.207,2:34:42.317
but scientific narratives tell history of technology

2:34:42.317,2:34:46.394
and fiction narrative that history about about technology

2:34:46.394,2:34:53.076
and leave room to very strange things that are coming up to be reality right now

2:34:53.076,2:35:03.283
for instance imagining that there are robots everywhere like in the drawings helping children helping elder people and bringing parcels to homes and so on

2:35:03.283,2:35:07.522
and making love with a robot find something that you can imagine

2:35:07.522,2:35:17.990
but these two images are also counterbalanced by the fact that we already have uh virtual girlfriends in Japan

2:35:17.990,2:35:26.809
and so this wasn't essay and and the papers in helping for elder people in their homes

2:35:26.809,2:35:34.121
so we are not quite far from scientific and fiction narrative in the reality that we are living

2:35:34.121,2:35:36.879
but the most interesting is not that

2:35:36.879,2:35:40.470
okay we can explore and explore and explore these fictional narratives

2:35:40.470,2:35:47.299
but these narratives end up being storytelling for robotics organizations and enterprises

2:35:47.299,2:35:52.847
first there are a lot of people (who) are telling us that this is the story this is a theological narrative

2:35:52.847,2:35:58.038
we are going towards the inescapable origin of robots in society

2:35:58.038,2:35:59.919
and that's almost human in society

2:35:59.919,2:36:07.885
and there are two famous enterprises that use a lot of media technologies such as YouTube

2:36:07.885,2:36:14.919
to produce different videos, Hanson Robotics and Boston Dynamics.

2:36:14.919,2:36:18.074
They are very famous and the first one is created Sofia.

2:36:18.074,2:36:24.719
This human shape robot face which is able to have a conversation with the humans

2:36:24.719,2:36:36.108
And these are very famous very sports robots that are keen to accomplish very very difficult motions

2:36:36.108,2:36:44.259
and these are very spectacular performance and they are broadcast intentionally by these enterprises

2:36:44.259,2:36:48.639
and this is fascinating for the wide audience and a lot of people discussing this as

2:36:48.639,2:36:50.301
"oh this is the future robots"

2:36:50.301,2:36:58.120
you see that women robots and these these very strong and even military robots and,

2:36:58.120,2:37:01.200
but this is upsetting for the robotician I'm working with

2:37:01.200,2:37:08.732
they said okay this is just spectacular things but this is not the reality of robotics as it is developing right now

2:37:08.732,2:37:18.449
but interestingly these same atoms to broadcast the the performance of robotics brings about dystopian scenario

2:37:18.449,2:37:29.760
and this is all except for the killer robot down in the slide but the two ones the robots is fighting back


2:37:29.760,2:37:36.781
Boston Dynamics roadways is fighting back against human and Sofia from Hanson Robotics telling "okay I will destroy humans"

2:37:36.781,2:37:46.412
these are fake fake videos but this means that the kind of genius side of the of the coin

2:37:46.412,2:37:55.053
when you try to broadcast an utopian future and said okay we live with this very very powerful performance and very powerful robots

2:37:55.053,2:38:02.306
and immediately they are also contrary visions and contrary imaginations

2:38:02.306,2:38:09.730
and then it brings me, I'm almost finished, to the what I call the cultural walls in digital revolution

2:38:09.730,2:38:12.478
because my approach is also a sociological one

2:38:12.478,2:38:16.079
I'm trying to understand position discourse and framework of imagination

2:38:16.079,2:38:17.924
and the way there are intentions

2:38:17.924,2:38:24.210
and from this field work, I'm framed for ideative attitudes to AI and robots

2:38:24.210,2:38:25.693
especially robots in this case

2:38:25.693,2:38:30.608
what I call technologies that means engineers and technicians that are elaborating robots

2:38:30.608,2:38:35.065
and most of them told me that okay this is all but spectacular screen

2:38:35.065,2:38:38.629
and this is a software and we are trying to frame algorithm

2:38:38.629,2:38:42.188
and then to see to test the movement and the part of the law and so on

2:38:42.188,2:38:47.110
and this is quite long and quite rigorous way of of doing things

2:38:47.110,2:38:50.661
and on the other side they are what I call technologians

2:38:50.661,2:38:54.159
"don't leave guys that come on TV and write books"

2:38:54.159,2:38:58.394
and say "okay the future of the digital age will be robots everywhere"

2:38:58.394,2:38:59.760
sometimes they are the same

2:38:59.760,2:39:07.120
Elon Musk for instance, is a pure technology and the prophet of the digital age

2:39:07.120,2:39:11.916
and describe the future as a full of these devices

2:39:11.916,2:39:18.661
may be it for critic critics be it for kind of variation of this

2:39:18.661,2:39:24.079
also there are technophilians developers and users that are fascinated by these

2:39:24.079,2:39:30.879
new technologies and technophobians okay four positions but the surprise come by the fact that

2:39:30.879,2:39:38.879
we are not only and not really in a face-to-face confrontation with you on the one side those

2:39:38.879,2:39:44.799
who believe in the future of robots and robotics and say okay there are technologies we live robots

2:39:44.799,2:39:51.280
will be like gods like new angels like new spirits of the time and the other side technologies that

2:39:51.280,2:39:56.478
bring this back to the crude reality and saying that this is not exactly that this

2:39:56.478,2:40:04.318
we have to be rationalists this is all all but all that reality and more most of the time we find in

2:40:04.318,2:40:09.520
the scientific literature this kind of tension between rationality and irrationality but it's

2:40:09.520,2:40:14.799
much more complex than that because first I give two examples technologies for instance can

2:40:14.799,2:40:20.879
be technophobians and in my field work I met some people that create robots but fear the development

2:40:20.879,2:40:26.719
of AI in the same time these are the same people and this is the complexity of human feelings and

2:40:26.719,2:40:32.398
human attitudes and for instance on the other way technophilians people that like this

2:40:32.398,2:40:38.719
technology are not always always technologies and most of the user in your ignore the process on and

2:40:38.719,2:40:46.159
the design of creating technologies and finally technologies can inspire but not always and annoy

2:40:46.159,2:40:51.840
but also inspire technologies for instance we know that in France they are they have been not in

2:40:51.840,2:40:59.200
France not only but elsewhere invitation from the government and the organization and invitation

2:40:59.200,2:41:06.159
for scientists and authors to imagine matching and scenario for the for the future so it's not only

2:41:06.159,2:41:12.559
coming from the technological mid and slide and I'm finished and sometimes technologist

2:41:12.559,2:41:17.600
meets technology and there is at least one enterprise in France I'm doing field work with who

2:41:17.600,2:41:25.439
level their products enchanted tools and I set up even a marvel section because when they create AI

2:41:25.439,2:41:30.799
and robots they know that they are designed with their own history and the imaginary framework they

2:41:30.799,2:41:36.559
sell you the robots and the cultural and symbolic universe of the robot they all come together

2:41:36.559,2:41:42.398
and like Alice in Wonderland in the same time you cannot have without the others and

2:41:42.398,2:41:48.159
this kind of reconciliation in between fiction and science fiction between imagination and technology

2:41:48.159,2:41:56.000
then this is thanks to imagination robots then there are more much more in the line of

2:41:56.000,2:42:03.040
social exception acceptation and and this enterprise is supposed to be on the technologist

2:42:03.040,2:42:11.359
really rationalist regional side leave room for imagination and help this creative

2:42:11.359,2:42:19.520
relationship with robots and a.m and blur the frontiers and give party ground for imagination

2:42:19.520,2:42:27.200
I come from the east side of the of the creators of rob and at final reflection just a sum up of

2:42:27.200,2:42:34.079
these points this is all again an ongoing research and these are some results but not all the results

2:42:34.079,2:42:40.559
this paper was just to reflect upon the issues of sciences I determined to a digital revolution

2:42:40.559,2:42:46.559
and a very specific object in digital revolution especially robots and the anthropological point

2:42:46.559,2:42:51.600
of view that has been adopted here was from the bottom from the actor's point of view

2:42:51.600,2:42:57.840
and how and why and who produce what kind of technological imagination or imagination

2:42:57.840,2:43:04.639
projected on technologies and these human shape devices that are present here today are a good

2:43:04.639,2:43:11.520
example but are not the only one and all have been said now I might be counter balanced and

2:43:11.520,2:43:16.879
critically converted to other devices and other conditions of producting and using these

2:43:16.879,2:43:24.318
technologies of course these are technologies are also source of different kind of images and

2:43:24.318,2:43:32.318
surrounded by a different framework of imagination but my conclusion is creative imagination is not

2:43:32.318,2:43:38.559
always where we think it is and the appropriation of these devices in the media of artistic media

2:43:38.559,2:43:50.879
is a key evidence of this point but my look was on the technological media and the and widening

2:43:50.879,2:43:58.318
communities of roboticians and this imaginary cultural imaginary then can nurture or prevent

2:43:58.318,2:44:05.840
the advance of and in technologies I mean and this is my final conclusion we always from side to

2:44:05.840,2:44:11.760
side from the beginning of thinking about robots a and digital technology and producing them and

2:44:11.760,2:44:19.120
distributing disseminating them in in societies and culture think about the the very crucial role

2:44:19.120,2:44:29.920
of imagination it means images and ideologies surrounding these technologies thank you

2:44:29.920,2:44:36.955
thank you very much professor Obadia for wonderful presentation

2:44:36.955,2:44:46.239
and I love this kind of topics, so I have so many issues I'd like to discuss with you

2:44:46.239,2:44:53.439
but at first, I'd like to start the two three more presentation for this session

2:44:53.439,2:45:04.398
then I'd like to discuss all with us so the next I'd like to welcome miss Biin Shen from China

2:45:04.398,2:45:13.760
she's an artist and she's a great artist and I'm honored to be welcome(ing) here Biin Shen

2:45:13.760,2:45:21.680
could you please start your presentation? sure thanks Eto-san for the introduction

2:45:21.680,2:45:30.799
so today I'm going to share some of the experience I developed after I returned to China

2:45:30.799,2:45:53.600
so it's great to be here and so I'm sharing the screen now can you see it can you see it

2:45:53.600,2:46:06.478
sorry let me just, yeah so I will ask my avatar to do this presentation for me today

2:46:06.478,2:46:18.879
okay who okay

2:46:18.879,2:46:24.719
yes I can hear you no doubt that technology has played an increasingly important role

2:46:24.719,2:46:30.639
since the 20th century humans have to face multiple crisis and dilemmas

2:46:30.639,2:46:39.279
from nature society and humans themselves. In such a closely interconnected world can the collisions

2:46:39.279,2:46:51.200
of different cultures and ideas inspire creations that helps technology develop the better solutions

2:46:51.200,2:46:57.920
hello everyone my name is Biin Shen thanks to Dr. *either(？)* for the invitation it's my great

2:46:57.920,2:47:03.120
pleasure to be here with other professionals at this workshop

2:47:03.120,2:47:09.359
I'm interested in the relationship between humans and technology to be more specific

2:47:09.359,2:47:15.040
I'm interested in how humans perceive or understand technology in a different culture

2:47:15.040,2:47:20.239
I have studied at m8 design interactions with professor *raby (?)* at the London Royal

2:47:20.239,2:47:30.239
College of Arts that's also why a part of my work includes speculative future scenarios

2:47:30.239,2:47:37.600
technology has been around since the dawn of humanity from stones for hunting to sticks to join

2:47:37.600,2:47:44.159
all of which are the products of technology in human society in this time although

2:47:44.159,2:47:51.920
technology is presented similarly in general due to the globalization nowadays since I moved back

2:47:51.920,2:47:55.040
I have found a common phenomenon in China

2:47:55.040,2:48:05.920
people have a pretty different view of technology than what I haven't seen in other countries

2:48:05.920,2:48:09.439
there is a park at center of beijing called

2:48:09.439,2:48:14.799
temple of heaven which seems to have become a testing ground for local creativity of

2:48:14.799,2:48:25.279
innovation even the toilet in this park have equipped it with face recognition technology

2:48:25.279,2:48:31.359
going to the loo in his park must not be an overly urgent task like in no times you can

2:48:31.359,2:48:36.398
only get the pieces of toilet paper after taking off your head and your glasses and staring at the

2:48:36.398,2:48:43.600
machine for three seconds the slowly dripped toilet paper is limited each time so if you

2:48:43.600,2:48:51.439
need more you may have to repeat the progress a few times before go into the toilet oh and

2:48:51.439,2:49:00.799
you can also get the toilet paper from the front looking of pikachu I have texted through my phone

2:49:00.799,2:49:05.439
there are many more cases here from a noodles performance robot

2:49:05.439,2:49:12.559
to a piano that can grill lamp kebabs to the Shenzhen's smartphones Chinese citizens

2:49:12.559,2:49:20.239
have unique optimistic altitudes on technology these attitudes re-establishments how they live

2:49:20.239,2:49:29.040
in their living environment which also influenced my art creations

2:49:29.040,2:49:35.680
the ancient Chinese cosmology there's a set of thoughts and rules behind the seemingly magical

2:49:35.680,2:49:45.040
talisman it is a virtual miss blended with reality such as rim making ceremony and at the same time

2:49:45.040,2:49:52.239
is the most sensory reflection of how people at each time have understood their natural

2:49:52.239,2:50:01.040
environment resembles the way how algorithms and data shapes are meant *fulu(?)* is a thousand talisman
@@@
2:50:01.040,2:50:09.120
that uses writing a meditation spell and spiritual power to scare away evil spirits attract fortune

2:50:09.120,2:50:16.639
or perceived peace in the space they are hung up or paced onto fulu is a drawing consisting

2:50:16.639,2:50:24.398
of Chinese characters with a mythological origin more than writing that merely describes the word

2:50:24.398,2:50:32.478
these characters have a magical relationship with them that allows them to act upon reality nowadays

2:50:32.478,2:50:39.680
the word of network's timo lecra gradually adopts and even replaces reality benefit tissue's

2:50:39.680,2:50:46.879
narrative of data becomes resources or even capsule the emergence of blockchain technology

2:50:46.879,2:50:54.239
and its decentralized worldview make it possible for internet nomads to build a better life

2:50:54.239,2:51:02.318
and these fictions are often regarded as objective depictions of reality

2:51:02.318,2:51:10.000
the character "Shu" in old Chinese means method skill extending from the meaning of the past

2:51:10.000,2:51:16.318
"Shu" also expressed both technology and the witchcraft which presents fiction there are also

2:51:16.318,2:51:24.079
cases of fictional transformations of reality in the records of dynasty in the novel heroes

2:51:24.079,2:51:31.439
of wood marine may eventually their depictions of diced monks and rivers who armed solely with diced

2:51:31.439,2:51:42.000
tools and witchcraft were able to overcome the machines and bring liberation for exploited people

2:51:42.000,2:51:49.760
continuing with this fiction or ancient wish of the Qing Dynasty I have created a speculative work

2:51:49.760,2:51:57.359
a series of contemporary fools for the society that is entirely overtaken by technology

2:51:57.359,2:52:04.318
this attempts to help people break the current human dilemma that both by the technology

2:52:04.318,2:52:10.000
and to explore the value of fictional realities

2:52:10.000,2:52:15.279
in this work I invited Hong Kong calligrapher *quinzo(?)* to invent

2:52:15.279,2:52:21.439
some food together to harness the invisible magnetism of algorithms in combination with

2:52:21.439,2:52:28.159
ancient beliefs for example the image on the screen is for bitcoin holders it can

2:52:28.159,2:52:36.879
convert any electronic devices into a bitcoin mining machine for attracting more bitcoins

2:52:36.879,2:52:55.120
we decided to let this alternative future so so now you can get those flu online

2:52:55.120,2:52:58.000
technology

2:52:58.000,2:53:07.439
new techniques a type of liberation and autonomy or just enough

2:53:07.439,2:53:17.840
use in space be liberated or trapped

2:53:17.840,2:53:22.478
in his book

2:53:22.478,2:53:28.719
only

2:53:28.719,2:53:35.920
thoughts have succeeded in tips but

2:53:35.920,2:53:43.680
also helped general products not all Asian

2:53:43.680,2:53:59.439
essentially in the exact nature like this

2:53:59.439,2:54:04.159
hmm

2:54:04.159,2:54:08.559
peace on

2:54:08.559,2:54:12.719
is is it disconnected

2:54:12.719,2:54:20.959
hello b sound are you here hello okay I think I saw some icons appear on my laptop said

2:54:20.959,2:54:27.760
connection is not good can you hear me now can you hear me now yes yes

2:54:27.760,2:54:45.040
okay so I will start sharing again okay okay can I say it yes okay cool

2:54:45.040,2:54:49.040
you

2:54:49.040,2:54:58.159
to allow the public to encounter their world anew a German noise assignment transported 1999

2:54:58.159,2:55:04.959
used smartphones on trolley surreal streets of Berlin and google maps recognized this activity

2:55:04.959,2:55:11.600
by turning a green street red and automatically producing a virtual traffic jam on the map

2:55:11.600,2:55:17.439
the fictional activity also affected the physical world where smart navigation

2:55:17.439,2:55:28.000
directed cars to alternative routes to avoid being stuck in this traffic this is not racket

2:55:28.000,2:55:37.279
poses potentially to generate fictions often take as accurate attentions of reality another example

2:55:37.279,2:55:44.159
is Sunday island image at the right side was featured by google earth through their satellites

2:55:44.159,2:55:52.159
imagery and market in the contemporary digital charts such as google maps from 1876 until October

2:55:52.159,2:55:59.200
2012 when scientists finally discovered that the island have never existed the marina favor is a

2:55:59.200,2:56:05.680
network commissioned by unesco creative cities to critique the relationship between humans and

2:56:05.680,2:56:12.559
technology as game is one of the common mechanism used in my creative practice I have built a

2:56:12.559,2:56:19.120
telephone game with the artificial intelligence program tits translated in his work the text

2:56:19.120,2:56:25.600
is translated between 10 rooted and distant language families to decipher the original text

2:56:25.600,2:56:31.840
after the text has been translated and re-translated the original meaning is lost and the

2:56:31.840,2:56:39.760
cyber formatted linguistic endpoints is obtained the project results from negotiating questions

2:56:39.760,2:56:46.719
such as chameleon be accurately represented in translation from human accessibility to machine

2:56:46.719,2:56:54.478
logic what does it say about us trusting the perfection of computers over the sentimentally

2:56:54.478,2:57:00.879
of humans using these questions as a foundation running human or philosophical

2:57:00.879,2:57:10.159
text through a programmatic data obscures the language mechanically the resulting text

2:57:10.159,2:57:16.559
visual images its final step relieves on the intuitive and imprecise thinking

2:57:16.559,2:57:24.159
that mirrors human perception english writer and creative

2:57:24.159,2:57:33.359
we only see what we look at to look is an act of choice I think art is particularly important

2:57:33.359,2:57:39.439
in this area than ever as everything in its reality is attached to capsule

2:57:39.439,2:57:47.520
by reviving the power of fiction art change the real world in the current technological context

2:57:47.520,2:57:54.079
to generate awareness for technology for work citizens to rethink their current states

2:57:54.079,2:58:04.559
to catalysts for the better futures and that's my talk today thank you very much

2:58:04.559,2:58:13.120
oh wow oh thank you very much your presentation is also an art hard work

2:58:13.120,2:58:20.398
very beautiful thank you very much yeah yeah thank you very much

2:58:20.398,2:58:28.000
i have many questions to you but I'd like to proceed to the next presentation

2:58:28.000,2:58:35.920
then and let's discuss so I'd like to welcome mangaly and martin mozarix from inaliya

2:58:35.920,2:58:45.200
so could you please start your presentation yes I'm sharing my screen thank you

2:58:45.200,2:58:49.920
and that's

2:58:49.920,2:58:56.398
oops so

2:58:56.398,2:59:07.840
is it working yes it is indeed so thank you again for inviting us and my name is Magali and

2:59:07.840,2:59:14.318
in the name of INRIA, CNRS, and Lucia and Terra Numerica we would like to to thank you

2:59:14.318,2:59:25.279
you Dr. Koichiro Eto-san for this invite and also the french and Japanese foundation and early kid

2:59:25.279,2:59:30.639
i'm sorry but our presentation is going to be very different because it's to share the

2:59:30.639,2:59:38.159
project we are working on at the moment in help maritime in the south of France sophia antipolis

2:59:38.159,2:59:44.000
and thank you to all of you for your excellent and exciting presentation and

2:59:44.000,2:59:50.559
i'm still very very impressed by being shane as well and it's going to be hard

2:59:50.559,2:59:58.079
to talk after her so Terra Numerica is digital sciences at your fingertips it's

2:59:58.079,3:00:04.079
something like we would like people to discover explore and experiment

3:00:04.079,3:00:13.840
so why Terra Numerica because like gravity digital is like everywhere and yet

3:00:13.840,3:00:22.318
digital till divide

3:00:22.318,3:00:29.840
people know how to use their phone their laptop but they don't know how what's behind it and

3:00:29.840,3:00:38.799
for Terra Numerica it's very important to engage people and and and share with

3:00:38.799,3:00:47.840
them so they can be independent with digitals and what's going on in this in this a new world

3:00:47.840,3:00:59.520
so very often we hear that these are not my cup of tea and despite the very good quality of

3:00:59.520,3:01:07.120
qual of science mediation with high attendance at science fair open doors conferences

3:01:07.120,3:01:16.043
courses digital is not yet considered not as a part of our culture as art is

3:01:16.043,3:01:26.026
so therefore, we sorry I'm not very up, so therefore Terra Numerica wants to

3:01:26.026,3:01:31.875
disseminate the knowledge to the largest possible number of people,

3:01:31.875,3:01:44.879
and we aim at being a good vector for digital sciences in education and then bring equal opportunities for everybody boys and girls

3:01:44.879,3:01:53.200
also why Terra Numerica in our territory it's a very rich territory in interactions with

3:01:53.200,3:02:03.279
arts as you may know the south of France *alpha 19 bar(?))* provence (name of a province?)

3:02:03.279,3:02:13.520
was, is still a very attractive place for artists so many came and stay and and produce in in the

3:02:13.520,3:02:24.000
area it's a very rich territory for art schools and like victorian studios as recently reopened

3:02:24.000,3:02:34.398
so cinema interactions lots of students and in society police and in nice and too long as well

3:02:34.398,3:02:45.680
a lot of research centers and private companies so very big nice area to to share and to to carry on

3:02:45.680,3:02:50.879
so the main goal of Terra Numerica was to bring together the whole digital sciences

3:02:50.879,3:03:01.439
actor which were on our territory and it was to not build well build something new but also

3:03:01.439,3:03:08.719
bring together all the people to make their experience and expertise in scientific meditation

3:03:08.719,3:03:17.600
their innovation creativity co-activities stronger also we very we're very keen in training

3:03:17.600,3:03:29.120
teachers professors and and sharing devices all devices around digital sciences

3:03:29.120,3:03:33.279
so Terra Numerica is a project still

3:03:33.279,3:03:42.159
it started we are now very I'm sorry sorry sorry sorry he lost my

3:03:42.159,3:03:51.439
we are now supported by our two funding members *cnrs India and universite cote d'azur(?)*

3:03:51.439,3:04:01.120
we we have fully members from different areas like research and higher education laboratories

3:04:01.120,3:04:10.398
schools association private companies and local authorities as well our goal is to finally have

3:04:10.398,3:04:20.639
a big space to share and to show digital sciences but not only all the earn their interactivities

3:04:20.639,3:04:32.719
but also we are very keen on going in mainly in *interland(?)* area because lots of secondary

3:04:32.719,3:04:43.439
schools high schools multimedia libraries don't always have access to those opportunities

3:04:43.439,3:04:53.760
we we have very open we are very open-minded and we've got like at the moment 150 people

3:04:53.760,3:05:01.040
working all together and including citizens students scientific administrative

3:05:01.040,3:05:07.200
staff artists everybody is is very welcome

3:05:07.200,3:05:18.398
so to give you a brief history of the project the project was born in into December 2018.

3:05:18.398,3:05:30.000
we were only four at the moment so in in 2 2019 we had to present and convince people and finally

3:05:30.000,3:05:38.318
we got a name and a logo which is Terra Numerica we got our first funding and first a key

3:05:38.318,3:05:55.279
achievement for Terra Numerica in 2020, then 2021 It was time for our, sorry our

3:05:55.279,3:06:02.719
research centers to sign an agreement and to encourage us to to carry on

3:06:02.719,3:06:10.478
so 2020 is 2022 is a big step for us because we are going to have a new pad as we said a very

3:06:10.478,3:06:19.200
big space 500 square meters where we are going to put down everything and it's going to be

3:06:19.200,3:06:26.879
able a place for sharing for researchers and people citizens to come and enter and

3:06:26.879,3:06:38.478
visit visitors and attend any kind of activities and the final goal for Terra Numerica in 2025

3:06:38.478,3:06:47.600
with the help of the local authorities is to open a dedicated place

3:06:47.600,3:06:56.398
to science meditation sorry meditation popularization of digital sciences and

3:06:56.398,3:07:04.000
we had the confirmation a few months ago so we are going to have like

3:07:04.000,3:07:12.318
5500 meters just for Terra Numerica, and just next to it, same place in Sophia Antipolis

3:07:12.318,3:07:21.279
5500 square meters for art and science linked to Terra Numerica and in connections

3:07:21.279,3:07:28.239
and after that the adventurers goes on we've got to carry on and work and produce and invent

3:07:28.239,3:07:36.959
and be different and attract more people so this is the place we we are going to

3:07:36.959,3:07:45.040
invest very soon where people are will be able to come and and visit and

3:07:45.040,3:07:52.639
it will be like the digital science fair all your all year round sorry and what we want is

3:07:52.639,3:08:03.279
to support innovative thinking inspire create share with everybody who's happy to come and

3:08:03.279,3:08:12.639
also we've got a little well not a little we would like to develop art and science in our project

3:08:12.639,3:08:19.200
and so just let open the windows on art and science and

3:08:19.200,3:08:22.869
as Picasso said everything you can imagine is real,

3:08:22.869,3:08:27.379
and this is what we are doing with Terra Numerica but not only

3:08:27.379,3:08:35.912
so we've got an agreement with Espace Art Concret de Mouans Sartoux and we are going to work

3:08:35.912,3:08:42.719
we are already working with them like Jean-Pierre as well showed you his project he's going to work

3:08:42.719,3:08:49.760
with with them as well and we would like to cross views between artists and scientists

3:08:49.760,3:08:56.959
so that could be a different level, like for instance the first example is Robert Delaunay

3:08:56.959,3:09:04.079
and you can as an artist, the creation and what an artist at INRIA can create

3:09:04.079,3:09:15.040
around the Delaunay Triangulations producing producing algorithm so that's an example

3:09:15.040,3:09:23.600
another example could be that that's a neural networks from another artist at INRIA,

3:09:23.600,3:09:32.159
and how your imagination could interpret neural networks in a different way

3:09:32.159,3:09:40.159
one of our scientists Frederick Avi who could not be there and Dorian Mazurik they both work

3:09:40.159,3:09:51.760
with this Espace Art Concret and for instance this is the work of Carl Andre which is a famous sculpturer,

3:09:51.760,3:09:57.051
American sculpture and it's the queens of, on the work of art,

3:09:57.051,3:10:04.605
and it's mixing arts, mathematics, and algorithm as you can see.

3:10:04.605,3:10:10.719
Also we've got heart is everywhere and there is another

3:10:10.719,3:10:19.359
project which is a spiral is in shape and it's an approach a multi-disciplinary approach and in this

3:10:19.359,3:10:28.318
case we want to erase awareness of observation reflection via the spiral as a mathematical

3:10:28.318,3:10:37.200
object or sharing with science and technology but not only like for instance the origami

3:10:37.200,3:10:46.318
origami to us could be a way to also introduce deep learning but very *vulgarated(?)*

3:10:46.318,3:10:55.520
but deep learning as you repeat the same gesture to train and to make your origami become alive

3:10:55.520,3:11:02.079
so that could be you know lots of connections to explain science and the interconnections between

3:11:02.079,3:11:09.439
heart history of art and and whatever okay so we are

3:11:09.439,3:11:17.680
beginning to be a bigger project with a lot of ambitions and any contributions would be very very

3:11:17.680,3:11:25.200
welcome, we can share with you seminars creative and innovating project

3:11:25.200,3:11:32.238
and also from what we heard this morning new scientific research approaches

3:11:32.238,3:11:42.719
and it would be very important for us to carry on any kind of collaboration so

3:11:42.719,3:11:53.279
this is just a little video I hope it works and

3:11:53.279,3:12:12.959
huh

3:12:12.959,3:12:15.520
oops

3:12:15.520,3:12:22.719
so thank you very much to ari gatou gozaimasu we will we heard about your

3:12:22.719,3:12:28.398
summer school at the beginning and we would be very happy to maybe collaborate with you

3:12:28.398,3:12:37.680
also in next November in society police at Indriya we're on organizing an *aca(?)* tech with

3:12:37.680,3:12:44.959
young students and researchers and one of the major group research area would

3:12:44.959,3:12:52.559
be heart and sciences because we believe we can create and do lots of new things

3:12:52.559,3:13:03.760
and we we've got to in in the area we also hold the project *troisi ah(?)* Koichiro Eto-san

3:13:03.760,3:13:08.639
you you've already heard about it so you could have a lot of interactions

3:13:08.639,3:13:18.959
around AI with a lot of scientists but not only twice a year Terra Numerica have

3:13:18.959,3:13:27.520
called for projects so we've got little finance to give the opportunity to artists or to scientists

3:13:27.520,3:13:38.719
to collaborate and to work together and being a non-artist and a non-scientific and living with

3:13:38.719,3:13:48.079
living and working with scientific and artists I believe that there is no that's it's not a

3:13:48.079,3:13:54.959
different word it's the same word sometimes as Jean-Pierre and some of you already said

3:13:54.959,3:14:02.639
the communication the the wording is not the same but the creativity and your sensitivity is just

3:14:02.639,3:14:12.159
the same always, I often hear mathematician say oh I'm so happy my algorithm is so beautiful

3:14:12.159,3:14:22.879
and it's in the same aspect that an artist could share his whatever production and also my final

3:14:22.879,3:14:31.398
sharing is next time we would be very honored to make a little video for Terra Numerica

3:14:31.398,3:14:38.639
or whatever and talk with now Tokui-sensei and maybe have his music

3:14:38.639,3:14:46.639
in back in the background to be more innovative thank you again (in Japanese) arigatou gozaimasu!

3:14:46.639,3:14:53.760
thank you very much for your presentation Magali-san then our presentation was

3:14:53.760,3:15:02.879
finished for session two so we'd like to start a discussion of of this session

3:15:02.879,3:15:12.639
then thank you thank you for all then I'd like to start a question to from myself

3:15:12.639,3:15:23.680
so why do you say can you hear me yeah I do yeah maybe you you have a limited time to so I'd like

3:15:23.680,3:15:32.799
to start question for you no no I i actually have plenty of time because if if it's

3:15:32.799,3:15:37.040
a quarter to ten two two up past 12 in France this is

3:15:37.040,3:15:43.359
one hour left I'm in Great Britain now so I have a lot of time not a lot but I have time

3:15:43.359,3:15:51.680
okay thank you I I'd like to ask you the many questions but at the first one point

3:15:51.680,3:16:00.238
how do you think the differences between the west and the east was for thinking about the

3:16:00.238,3:16:10.000
dystopia scenario for the future I i think that there is a how can I say increased by from the

3:16:10.000,3:16:20.159
fiction novel for example Frankenstein as you know a scientific science fiction novelist

3:16:20.159,3:16:29.760
Isaac Asimov named it as a syndrome of a Frankenstein so how do you think the

3:16:29.760,3:16:40.159
scenario is different for the west and the east oh the question of cultural relativity I heard that

3:16:40.159,3:16:47.120
well, we have the same I have, I'm jumping aside and I'm coming back to the discussion right

3:16:47.120,3:16:54.238
now. I'm also working on another media-tech and the cultural creator named the zombie and you

3:16:54.238,3:16:59.439
know there is huge discussion regarding if it's a production of the western imagination and if it

3:16:59.439,3:17:05.920
can also be rooted in the in non-western culture and civilization given that the relationship

3:17:05.920,3:17:12.478
in between the body culture the imagination of after after death and so on are quite different

3:17:12.478,3:17:19.120
from way on the way to another depending not only on culture but and I'm getting back

3:17:19.120,3:17:28.639
to the point on history you know that the the on not only culture but also history

3:17:28.639,3:17:34.000
for instance the the degree of historical trauma that you have for instance for walls

3:17:34.000,3:17:40.559
and the very specific relationship that you can have with technology and for instance you

3:17:40.559,3:17:46.879
Japan invented Godzilla and now this is the universal feature now the character that we

3:17:46.879,3:17:54.398
we can see everywhere but you invited it and and this now belongs to the global popular culture

3:17:54.398,3:18:03.120
and it can be recognized everywhere and so I think that there are framework for dystopian scenarios

3:18:03.120,3:18:12.079
similar on some aspects with a local variations regarding the very specific national history

3:18:12.079,3:18:18.639
let's say on the background of global history but but national histories for instance

3:18:18.639,3:18:26.159
and that's why there is a huge distribution of of this dystopian scenarios but if you

3:18:26.159,3:18:32.159
allow me just one more second I'm a bit talkative but just one second this dystopian

3:18:32.159,3:18:38.879
scenarios has also grounds for the acceptation of this for instance the fact that we all know

3:18:38.879,3:18:48.000
who is Frankenstein creator and we all accepted that we can create such let's say animals or

3:18:48.000,3:18:55.040
or human-like creatures regardless of the the outcomes and the fact that the creator can kill

3:18:55.040,3:19:03.760
the the create creator can kill the creator but you can fear a very specific scheme or object or

3:19:03.760,3:19:10.879
sign of symbol but accept it and dystopian can also be imaginary indeed

3:19:10.879,3:19:19.920
geological ideological facilitator for the acceptation of these things in my opinion

3:19:19.920,3:19:26.079
interesting I have this kind of a scientific fiction story

3:19:26.079,3:19:34.238
there are so many cultural background differences so maybe we can deepen this kind of stories

3:19:34.238,3:19:44.639
very much but I'd like to make broader to this topics so I'd like to ask you being

3:19:44.639,3:19:54.478
some how do you think the described stories from the east side and your presentation is

3:19:54.478,3:20:05.520
wonderful and also it's playful so I'm very interested in your story to a playful future

3:20:05.520,3:20:12.000
ah president can you can repeat the question again sorry I think the internet is not

3:20:12.000,3:20:22.799
evil in the you created the future scenario as a good site or a prayer site

3:20:22.799,3:20:30.478
I'm very interested in where did you come from this kind of attitude altitude you mean

3:20:30.478,3:20:39.040
the work I just created oh yeah okay well I think it's quite it's quite complicated because as

3:20:39.040,3:20:47.840
an artist I think any experience is going to our creation so I think my creation slightly

3:20:47.840,3:20:55.680
starts changing because I was moved back to China since 2020 and from then I think the whole

3:20:55.680,3:21:01.279
involvement and also the people how people are using the technology and the people's optimistic

3:21:01.279,3:21:08.238
altitudes on the technology in this whole environment is quite shocked me so so that that's

3:21:08.238,3:21:14.879
you can see that's my analyze of how what happens in these environments like from my slides

3:21:14.879,3:21:22.238
just in my presentation and so from that I was thinking compared to the study I would

3:21:22.238,3:21:31.680
compare to the the life experience when I was in London and I seen like quite different view

3:21:31.680,3:21:39.760
in China that everyone can so close engage with the technology that they bring the technology

3:21:39.760,3:21:49.600
fragments into their daily lives and then so in that case I think here everybody is artists

3:21:49.600,3:21:56.879
they are creating they're creating their how can I say they use their creation to

3:21:56.879,3:22:06.478
actually build the future day by day person by person and so when I seen this also I was raising

3:22:06.478,3:22:13.200
myself as an artist was the responsibility of being an artist in this technological arrow

3:22:13.200,3:22:20.398
so basically I'm more like critics on technology through my artworks and uh

3:22:20.398,3:22:29.920
and yeah that's that's that's experience again from from the from Beijing from China here

3:22:29.920,3:22:33.279
I'm not sure if I don't say it

3:22:33.279,3:22:41.359
yeah it's wonderful answer that everybody is an artist in China yeah

3:22:41.359,3:22:47.920
it's quite like you can't really you can't really feel which parts is the reality and

3:22:47.920,3:22:59.040
which part is fiction it's kind of all mixed up together the things you see in

3:22:59.040,3:23:07.439
it may next day appear in a daily life like in China you never know every day is a surprise

3:23:07.439,3:23:14.478
interesting thank you very much

3:23:14.478,3:23:27.279
for sang can you hear me magazine I have a question for you that how would you like to

3:23:27.279,3:23:37.120
make a place to collaborate with artists in your project can you hear me

3:23:37.120,3:23:41.040
nobody saying

3:23:41.040,3:23:46.799
he is not in a list of the names anymore wow

3:23:46.799,3:23:50.398
okay then

3:23:50.398,3:23:56.318
she came here again

3:23:56.318,3:24:04.398
if somebody have questions to speakers you can feel free to uh

3:24:04.398,3:24:14.238
on microphone then start to talk or please say something from chat

3:24:14.238,3:24:18.478
can you hear me

3:24:18.478,3:24:28.000
yes sorry *shiro(?)* I lost you and I had to connect again ah okay so I'd like to I'll repeat the

3:24:28.000,3:24:36.079
question to you okay thank you I have a question is it any plan to make a collaborative

3:24:36.079,3:24:45.680
collaborative space in your project is there any future plan to collaborate with artists

3:24:45.680,3:24:54.159
oh yes indeed we we would like to to do that I mean Jean-Pierre is already an example

3:24:54.159,3:25:04.719
so far we have approached the Art Concret in Mouans Sartoux, but we would like to carry on and extend and

3:25:04.719,3:25:12.159
even outside the area the national I mean the France or elsewhere because like

3:25:12.159,3:25:23.920
we are going to have one 1 500 meters dedicated to art and science and it's very important to

3:25:23.920,3:25:32.000
to collaborate and to extend and so there are so many local artists as well it's a very rich

3:25:32.000,3:25:39.520
territory so yes we are very keen on on collaborating Koichiro with

3:25:39.520,3:25:44.799
you or any person who would like and also it is very important as you said

3:25:44.799,3:25:51.600
it's opening a new reflection on science aspects like with social environment

3:25:51.600,3:25:59.680
and with heart and the connections and I gather our project it's at uh

3:25:59.680,3:26:04.799
at a level just under your creativity

3:26:04.799,3:26:11.680
because for us the important is to share like we explain AI with a wooden

3:26:11.680,3:26:21.920
machine we've got lots of and it's to make people more confident and to show them that

3:26:21.920,3:26:31.200
digital a is everywhere but like art is everywhere as well to us so it's important that people trust

3:26:31.200,3:26:37.589
and feel more confident and it's like religion as Lionel,

3:26:37.589,3:26:42.435
I think it was Lionel (who) made (them) the relation,

3:26:42.435,3:26:46.502
I mean it's everyday you've got to convince people you've got,

3:26:46.502,3:26:55.279
and especially after what we've been through with the Covid you can all see that there is a lack of on

3:26:55.279,3:27:02.959
believing in science or in scientists so the problematics is everywhere and we've got to

3:27:02.959,3:27:08.959
carry on but yes we will be very happy to collaborate

3:27:08.959,3:27:17.920
I'm looking forward to collaborating with you yes we ideally we would we would have loved to welcome

3:27:17.920,3:27:25.040
you in March sometimes but because you are going back to Japan maybe next time with pleasure

3:27:25.040,3:27:33.359
Koichiro yeah thank you very much thank you so this is a time for discussion so is there any

3:27:33.359,3:27:54.159
questions between a speaker to a speaker we we are welcome to talk we have from you

3:27:54.159,3:28:04.238
i have one but meditate it will bring us very far okay I can try to jump here

3:28:04.238,3:28:10.639
since you work with the on the one side there is a close connection with artists and on the other

3:28:10.639,3:28:22.318
side you are working as in the heart of technology how do you get the issue of crafting

3:28:22.318,3:28:26.879
on the one side and creating on the other side all together

3:28:26.879,3:28:31.840
this is not an easy question this is a theoretical question I'm sorry for that but I know that there

3:28:31.840,3:28:38.159
are spaces right now in sciences where creation yeah you know crafting science is really inspired

3:28:38.159,3:28:53.520
by art and reciprocally so both of you are one of you how do you tackle this issue

3:28:53.520,3:29:01.840
well okay we have the main research area which is assistance for frail people

3:29:01.840,3:29:08.159
but at the same time we allowed us to wander

3:29:08.159,3:29:18.478
on other topics that are not really connected to our main research areas it happened in workshop

3:29:18.478,3:29:29.120
it happened in meeting well you know quite well that we have a lot of administrative meetings

3:29:29.120,3:29:38.719
and we try to make the best of them meaning that we have the opportunity to meet other

3:29:38.719,3:29:44.478
colleagues working in very different domains and what surprised me no doesn't surprise me but

3:29:44.478,3:29:53.680
what happened is that I see some kind of convergence in science as well meaning that

3:29:53.680,3:30:00.959
for example we have people trying to tackle numerical fluids problems and it just happens that

3:30:00.959,3:30:05.760
if you discuss with them during lunch you will see that they have

3:30:05.760,3:30:13.120
problems that are very similar to what problem you have and

3:30:13.120,3:30:19.760
you have developed algorithm for solving this problem they have developed their own algorithm

3:30:19.760,3:30:26.959
and it happens quite quickly frequently that well their tools may be quite useful

3:30:26.959,3:30:31.920
for us and reciprocally and in fact it's it's I will say it's just random

3:30:31.920,3:30:42.159
meeting so we just kiss with lawyers we discuss with biologists I have a biologist in my team

3:30:42.159,3:30:48.318
i will say just the open discussion

3:30:48.318,3:30:55.439
there is no systematic way to do it we have done a systematic approach at the beginning when we move

3:30:55.439,3:31:04.079
to industrial robotics to assistance robotics we spend two years making a lot of interviews with

3:31:04.079,3:31:12.079
customers help us medical community local authorities and really

3:31:12.079,3:31:17.920
it was very useful because we learned a lot of things we learned to avoid a lot of mistakes

3:31:17.920,3:31:23.760
which are very easy to make and I think that with artists it just happens that

3:31:23.760,3:31:31.359
it happens once a long time ago the world spread among the artists there is some team in

3:31:31.359,3:31:39.040
south of France which may help us to do whatever we want so this started accumulating and

3:31:39.040,3:31:49.439
the world spreads and that's it but there is no process for that in my opinion

3:31:49.439,3:32:02.719
thank you

3:32:02.719,3:32:12.238
sorry sorry so I was saying that in my first life at IRCAM when I was mostly working on

3:32:12.238,3:32:20.639
computer-assisted composition software tools we we had two kind of interactions between scientists

3:32:20.639,3:32:29.120
and artists in in the first situation the artist would come to the scientist with a problem

3:32:29.120,3:32:39.840
for instance a musical problem and would ask for help and expertise and algorithm and sometimes a

3:32:39.840,3:32:47.279
problem that was explained in a very lengthy way and seemed very complicated actually could

3:32:47.279,3:32:54.719
be solved with a very simple scientific or technological device or a simple algorithm

3:32:54.719,3:33:01.680
and sometimes a problem that seemed extremely simple to the artist and the artist thought that

3:33:01.680,3:33:05.359
he would really just need a little help to to achieve it

3:33:05.359,3:33:14.719
would actually become a huge scientific problem and maybe sometimes an unsolvable one

3:33:14.719,3:33:21.840
and this is very very interesting because it shows that the perception of complexity is very

3:33:21.840,3:33:29.520
different between artists and scientists scientists have issues of computability

3:33:29.520,3:33:37.840
which is a very difficult topic as as as you know and things that that are very obvious

3:33:37.840,3:33:46.478
in real life can become extremely difficult to model actually in in uh

3:33:46.478,3:33:54.159
a quantitative approach and sometimes the artists have a hard time understanding this because what

3:33:54.159,3:34:00.639
is simple for them and or complex and complicated for them it's totally different from what the

3:34:00.639,3:34:06.879
scientists would tackle as simple or complex so so we had this strange relationship in the

3:34:06.879,3:34:13.120
first place with the in the situation where the artist would come to the to the to the scientists

3:34:13.120,3:34:21.520
and asked so to speak for a service we had another kind of interaction which which went the other

3:34:21.520,3:34:27.439
way around so the scientists are also creative and creators except that they create scientific

3:34:27.439,3:34:34.799
theories or algorithms or models and they would come up with ideas of new models new algorithm

3:34:34.799,3:34:41.200
new fields and then they would talk about it because of course we have a lot of places to

3:34:41.200,3:34:48.238
talk workshops conferences seminars etc and then the artist would would come to the scientists and

3:34:48.238,3:34:54.318
say oh I never thought about that it's absolutely fascinating and it gives me an id for a new work

3:34:54.318,3:35:03.279
for a new piece maybe we can collaborate and so in this situation it it it would be it

3:35:03.279,3:35:09.359
would be the ideas coming from the scientist who would inform and influence the artist so that was

3:35:09.359,3:35:17.120
a traditional divide that was a traditional dichotomy between art and science as

3:35:17.120,3:35:25.520
a as a service-based relationship or art and science as a transfer or influence or transfer

3:35:25.520,3:35:30.959
of ids from one field to another it's two very different approaches and of course we we had

3:35:30.959,3:35:38.719
to cope with both but since I've been working on interactive and creative AI that is designing uh

3:35:38.719,3:35:44.398
kind of artificial create creatures that can live by themselves and interact on stage with musicians

3:35:44.398,3:35:51.520
now we're on in a very different situation because the the the concern now of the musician is how can

3:35:51.520,3:35:59.200
how can I have this artificial creature shut up for a moment because which is which is exactly

3:35:59.200,3:36:03.200
a question of control because we don't know really how to control them for instance we have

3:36:03.200,3:36:10.238
algorithm, AI algorithm, that generate music and do real-time machine learning in live situations etc

3:36:10.238,3:36:17.279
and they play music sometimes in a very smart way but they they they don't we see we still don't

3:36:17.279,3:36:27.680
have the cognitive model of intentionality and intrinsic motivation and all this that that makes

3:36:27.680,3:36:34.639
that that that can help us to decide when to start and when to stop doing something so generally

3:36:34.639,3:36:39.359
generally the the human who starts the computer and then the computer plays music it doesn't know

3:36:39.359,3:36:46.238
when to stop so so the the the human would would really like to have some more control over that

3:36:46.238,3:36:55.279
and so we so we are now moving to to to a paradigm of control and how to understand uh

3:36:55.279,3:37:05.200
control in the in the case where you have kind of artificial agents that that have a

3:37:05.200,3:37:13.439
that have a certain autonomy so the problem has totally shifted to to to this new issue of control

3:37:13.439,3:37:17.760
i think just what that

3:37:17.760,3:37:24.398
just one thing that I have to mention is that there is a parallel between in our collaboration

3:37:24.398,3:37:31.920
with that with a collaboration we have with doctors you have to be quite careful when you

3:37:31.920,3:37:39.040
do that for example if you go when you meet a doctor for the first time and tell him look you

3:37:39.040,3:37:46.478
have currently a medical process and I will teach you how to change it and to do it very efficiently

3:37:46.478,3:37:55.359
so you want to change everything then you are dead you have to learn to be incremental meaning

3:37:55.359,3:38:03.359
you have to simply state okay you have a process I will not change it I will just

3:38:03.359,3:38:11.600
help you on a given detail of this process to do it in a better way or to do it for you something

3:38:11.600,3:38:19.600
that you have currently doing we will avoid trying to do an example when you do a walking analysis

3:38:19.600,3:38:26.879
of a patient there is a classical test where you measure the time the guy takes to make 10 meter in

3:38:26.879,3:38:34.238
this straight line so so the surgeon is looking as at the chronometer

3:38:34.238,3:38:42.079
of looking at the way the guy is walking so the first thing we do is okay we will avoid you

3:38:42.079,3:38:46.159
looking at the chronometer because our machine will measure all the time for you

3:38:46.159,3:38:56.079
that's it they say okay because it was no big change for them and then we say well we can

3:38:56.079,3:39:00.398
measure also some of the things for example we have measured during this experiment this

3:39:00.398,3:39:09.040
particularity oh they say oh you can measure that so incrementally we add things we were able

3:39:09.040,3:39:18.238
to do since the very start of the program but we won't we don't want to say that at the beginning

3:39:18.238,3:39:27.760
and the doctors learned like the artists and when the request or the suggestion does not come from

3:39:27.760,3:39:37.120
us but from the doctors you have measured that but be possible to measure also that that we know we

3:39:37.120,3:39:44.318
have win and it's exactly the same process with artists in our first collaboration we were just

3:39:44.318,3:39:52.559
attacking with a small minor detail in the artwork showing it can be done and progressively

3:39:52.559,3:39:58.238
that you say oh you have been able to do that I would like to do another thing can you do it for

3:39:58.238,3:40:08.238
me and that's okay if you are these steps then you know that the collaboration will be quite fruitful

3:40:08.238,3:40:11.840
you have to be perfect

3:40:11.840,3:40:16.959
to fight your to fight your own mind we say okay we have this problem I know how

3:40:16.959,3:40:30.879
to deal with it completely and efficiently you have to learn that to be careful not do that

3:40:30.879,3:40:36.159
yes it is very smart approach and as you say the relation between artists

3:40:36.159,3:40:45.279
and scientists is a very delicate one and one has to treat it in a very delicate

3:40:45.279,3:40:48.879
yeah way you very much for

3:40:48.879,3:41:09.120
the cube okay and I think I we are almost running out of time for discussion so uh

3:41:09.120,3:41:40.799
no

3:41:40.799,3:41:48.318
okay okay I'd like to conclude this q a discussion session

3:41:48.318,3:41:56.159
and also this workshop so thank you very much for all participants

3:41:56.159,3:42:07.040
in this workshop you know for food for a discussion in this time so

3:42:07.040,3:42:17.359
can I across or who is a speaker for closing remarks yes I think you can you can conclude here

3:42:17.359,3:42:26.478
because I think Sebastian the chevalier *Jean Vivian(?)* had to left earlier so you can conclude

3:42:26.478,3:42:33.520
okay I'd like to conclude this workshop and there was a wonderful presentation

3:42:33.520,3:42:40.559
so many wonderful presentations and there's so many issues to how to

3:42:40.559,3:42:47.520
deepen the relationship between art and advanced technology in this society

3:42:47.520,3:42:56.719
so I am very thankful to all the participants and for speakers and audience thank you very

3:42:56.719,3:43:12.879
much for making this workshop possible so I'd like to to end this workshop thank you very much

3:43:12.879,3:43:18.318
thanks a lot thank you thank you very much

3:43:18.318,3:43:27.199
thanks everyone thank you thanks take care bye bye thank you bye